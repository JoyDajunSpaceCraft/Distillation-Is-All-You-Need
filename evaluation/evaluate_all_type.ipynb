{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbefc07-b555-480a-8d12-675e3baa629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the evaluation of all format of test data\n",
    "ground_truth_list = {\n",
    "    \"nfcorpus\":{\n",
    "        \"train\":\"./data/nfcorpus/train.nontopic-titles.queries\",\n",
    "        \"train_qrel\":\"./data/nfcorpus/train.2-1-0.qrel\"},\n",
    "    \"covid\": {\n",
    "        \"train_query\":\"./data/trec_covid/queries.jsonl\",\n",
    "        \"train_qrel\":\"./data/trec_covid/qrels/test.tsv\"},\n",
    "    \"touche\":{\n",
    "        \"train_query\":\"./data/touche/train.nontopic-titles.queries\",\n",
    "        \"train_qrel\":\"./data/touche/train.2-1-0.qrel\"},\n",
    "    \"dbpedia\":{\n",
    "        \"train_query\":\"./data/dbpedia-entity/queries.jsonl\",\n",
    "        \"train_qrel\":\"./data/dbpedia-entity/qrels/test.tsv\",\n",
    "        \"test_qrel\":\"./data/dbpedia-entity/qrels/dev.tsv\"},\n",
    "    \"scifact\":{\n",
    "        \"train_query\":\"./data/scifact/queries.jsonl\",\n",
    "        \"train_qrel\":\"./data/scifact/qrels/train.tsv\",\n",
    "        \"test_qrel\": \"./data/scifact/qrels/test.tsv\"},\n",
    "    \"msmarco\":{\n",
    "        \"train_query\":\"./data/msmarco/queries.jsonl\",\n",
    "        \"train_qrel\":\"./data/msmarco/qrels/train.tsv\",\n",
    "        \"test_qrel\":\"./data/msmarco/qrels/test.tsv\",\n",
    "        \"dev_qrel\":\"./data/msmarco/qrels/dev.tsv\"},\n",
    "    \"noval\":{\n",
    "        \"train_query\":\"./data/Noveleval/queries.tsv\",\n",
    "        \"train_qrel\":\"./data/Noveleval/qrel.txt\",\n",
    "        \"corpus\": \"./data/Noveleval/corpus.tsv\"},      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4cde0a-d5d5-41b1-b0b0-dea3f3244f63",
   "metadata": {},
   "source": [
    "## BM25 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1eb2e8e-bf05-4ea2-94dd-81f136237edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_list = {\n",
    "    # \"nfcorpus\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_nfcorpus_train.json\"}\n",
    "    # \"covid\": {\n",
    "    #     \"train\":\"../data/BM25/bm25_covid_train.json\"\n",
    "    #    },\n",
    "    # \"touche\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_touche_train.json\"}\n",
    "    # \"dbpedia\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_dbpedia_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_dbpedia_test.json\"},\n",
    "    # \"scifact\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_scifact_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_scifact_test.json\"},\n",
    "    \"msmarco\":{\n",
    "        \"train\":\"../data/BM25/bm25_msmarco_train.json\",\n",
    "        \"test\":\"../data/BM25/bm25_msmarco_test.json\",\n",
    "        \"dev\":\"../data/BM25/bm25_msmarco_dev.json\"},\n",
    "    # \"noval\":{\n",
    "    #    \"train\":\"../data/BM25/bm25_noval_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_noval_test.json\"}     \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b3d63-3f3a-4005-b5c1-ca7be6063d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BM 25\n",
    "import numpy as np\n",
    "import json\n",
    "# Function to calculate DCG for the top k documents\n",
    "def calculate_dcg(scores, k=5):\n",
    "    scores = scores[:k]  # Consider only the top k scores\n",
    "    return np.sum([(2**score - 1) / np.log2(idx + 2) for idx, score in enumerate(scores)])\n",
    "\n",
    "# Function to calculate NDCG for the top k documents\n",
    "def calculate_ndcg(query_data, k=5):\n",
    "    actual_scores = [int(hit['score']) for hit in query_data['hits']]\n",
    "    ideal_scores = sorted(actual_scores, reverse=True)\n",
    "    \n",
    "    dcg = calculate_dcg(actual_scores, k)\n",
    "    idcg = calculate_dcg(ideal_scores, k)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "for data_name, data in bm25_list.items():\n",
    "    # with open('/mnt/data/bm25_msmarco_test.json', 'r') as file:\n",
    "\n",
    "    train_data = data[\"train\"]\n",
    "    train_data = json.load(open(train_data))\n",
    "    \n",
    "    ndcg_scores = [calculate_ndcg(query, k=5) for query in train_data]\n",
    "    # Print average NDCG@5 across queries\n",
    "    average_ndcg = np.mean(ndcg_scores)\n",
    "    print(f'Average NDCG@5: {average_ndcg}')  # 0.18769179239453124\n",
    "\n",
    "    ndcg_scores = [calculate_ndcg(query, k=1) for query in train_data]\n",
    "    # Print average NDCG@5 across queries\n",
    "    average_ndcg = np.mean(ndcg_scores)\n",
    "    print(f'Average NDCG@1: {average_ndcg}') # 0.0968292943311626\n",
    "    \n",
    "    if \"test\" in data.keys():\n",
    "        test_data = data[\"test\"]\n",
    "        test_data = json.load(open(test_data))\n",
    "        ndcg_scores = [calculate_ndcg(query, k=5) for query in test_data]\n",
    "        # Print average NDCG@5 across queries\n",
    "        average_ndcg = np.mean(ndcg_scores)\n",
    "        print(f'Average NDCG@5: {average_ndcg}') # 0.5428988468795134\n",
    "    \n",
    "        ndcg_scores = [calculate_ndcg(query, k=1) for query in test_data]\n",
    "        # Print average NDCG@5 across queries\n",
    "        average_ndcg = np.mean(ndcg_scores)\n",
    "        print(f'Average NDCG@1: {average_ndcg}') # 0.4939091915836102\n",
    "    \n",
    "\n",
    "# Average NDCG@5: 0.18769179239453124\n",
    "# Average NDCG@1: 0.0968292943311626\n",
    "# Average NDCG@5: 0.5428988468795134\n",
    "# Average NDCG@1: 0.4939091915836102  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86523545-df4f-412d-b301-a000a9a59e6b",
   "metadata": {},
   "source": [
    "## GPT 3.5 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11eab47b-f94b-451c-b4b5-e251a9b6fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_num = 10\n",
    "GPT_list = {\n",
    "   # \"nfcorpus\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_nfcorpus_train.json\"}\n",
    "    # \"covid\": {\n",
    "    #     \"train\":\"../data/BM25/bm25_covid_train.json\"\n",
    "    #    },\n",
    "    # \"touche\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_touche_train.json\"}\n",
    "    # \"dbpedia\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_dbpedia_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_dbpedia_test.json\"},\n",
    "    # \"scifact\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_scifact_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_scifact_test.json\"},\n",
    "    \"msmarco\":{\n",
    "        \"train\":\"../data/GPT3.5/msmarco_train.jsonl\",\n",
    "        \"test\":\"../data/GPT3.5/msmarco_test.jsonl\",\n",
    "        # \"dev\":\"../data/GPT3.5/msmarco_dev.json\"\n",
    "    },\n",
    "    # \"noval\":{\n",
    "    #    \"train\":\"../data/BM25/bm25_noval_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_noval_test.json\"}     \n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3096a7b9-26a0-4220-bc2d-6f49802b5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# def dcg(scores):\n",
    "#     \"\"\"Calculate the Discounted Cumulative Gain for a list of scores.\"\"\"\n",
    "#     return np.sum([score / np.log2(idx + 2) for idx, score in enumerate(scores)])\n",
    "\n",
    "# def ndcg(relevances):\n",
    "#     \"\"\"Calculate the Normalized Discounted Cumulative Gain for a list of relevance scores.\"\"\"\n",
    "#     best_dcg = dcg(sorted(relevances, reverse=True))\n",
    "#     actual_dcg = dcg(relevances)\n",
    "#     return actual_dcg / best_dcg if best_dcg > 0 else 0\n",
    "def dcg(scores, k=5):\n",
    "    \"\"\"Calculate the Discounted Cumulative Gain for a list of scores up to position k.\"\"\"\n",
    "    return np.sum([score / np.log2(idx + 2) for idx, score in enumerate(scores[:k])])\n",
    "\n",
    "def ndcg(relevances, k=5):\n",
    "    \"\"\"Calculate the Normalized Discounted Cumulative Gain for a list of relevance scores up to position k.\"\"\"\n",
    "    best_dcg = dcg(sorted(relevances, reverse=True), k)\n",
    "    actual_dcg = dcg(relevances, k)\n",
    "    return actual_dcg / best_dcg if best_dcg > 0 else 0\n",
    "\n",
    "\n",
    "# re-rank is the new id we need to range\n",
    "def map_rerank_id(re_rank_id, scores):\n",
    "    scores = [int(score) for score in scores]\n",
    "    re_rank_id = [int(id) for id in re_rank_id]\n",
    "    new_scores = [scores[idx-1] for idx in re_rank_id]\n",
    "    return new_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65510eae-aaf9-4ec1-8066-f6d8cdfed389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG 1: 0.821705426356589\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "reverse_k = 5-k + 1\n",
    "for data_name, data_path in GPT_list.items():\n",
    "    \n",
    "    # Path to the JSONL file\n",
    "    file_path = '../data/GPT3.5/msmarco_test.jsonl'\n",
    "    \n",
    "    # Calculate NDCG for each line in the file\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        used_query = []\n",
    "        for line in file:\n",
    "            \n",
    "            data = json.loads(line)\n",
    "            used_query.append(data[\"query\"]) \n",
    "            # if data[\"query\"] in used_query:\n",
    "            if used_query.count(data[\"query\"])==4: # need to use the last one because it is inverse\n",
    "                re_rank_id= data[\"re_rank_id\"]\n",
    "                scores = data[\"scores\"]\n",
    "                scores = map_rerank_id(re_rank_id, scores)\n",
    "                ndcg_scores.append(ndcg(scores, reverse_k))\n",
    "   \n",
    "    \n",
    "    # Calculate the average NDCG across all queries\n",
    "    average_ndcg = np.mean(ndcg_scores)\n",
    "    print(f\"Average NDCG {str(reverse_k)}:\", average_ndcg)\n",
    "    # print(\"NDCG Scores for first 5 queries:\", ndcg_scores[:5])\n",
    "# Average NDCG 1: 0.8893586151764177\n",
    "# Average NDCG 5: 0.821705426356589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26c812-f7bb-4ee8-a726-9621c4e3cf19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
