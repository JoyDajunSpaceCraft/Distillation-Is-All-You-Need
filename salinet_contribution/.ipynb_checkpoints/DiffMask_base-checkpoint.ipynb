{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcc85e3-eddc-4dfa-9943-b15295b9b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置使用第二块 GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3a12e9-d758-4c77-80a2-0ed9b1c96d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class MaskConfig:\n",
    "    model: str\n",
    "    attn_heads: int = 0\n",
    "    mlps: int = 0\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    seed: int\n",
    "    name: str\n",
    "    path: str\n",
    "    workers: int\n",
    "    val_size: float\n",
    "\n",
    "@dataclass\n",
    "class TrainerConfig:\n",
    "    epochs: int\n",
    "    lr: float\n",
    "    momentum: float\n",
    "    weight_decay: float\n",
    "    batch_size: int\n",
    "    checkpoint_path: str\n",
    "    results_path: str\n",
    "\n",
    "@dataclass\n",
    "class DiffMaskConfig:\n",
    "    seed: int\n",
    "    mask: MaskConfig\n",
    "    data: DataConfig\n",
    "    trainer: TrainerConfig\n",
    "\n",
    "# 读取 YAML 配置文件\n",
    "with open('diffmask.yaml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n",
    "\n",
    "# 初始化配置对象\n",
    "config_data['trainer']['lr'] = float(config_data['trainer']['lr'])\n",
    "config_data['trainer']['momentum'] = float(config_data['trainer']['momentum'])\n",
    "config_data['trainer']['weight_decay'] = float(config_data['trainer']['weight_decay'])\n",
    "config_data['trainer']['batch_size'] = int(config_data['trainer']['batch_size'])\n",
    "config_data['trainer']['epochs'] = int(config_data['trainer']['epochs'])\n",
    "\n",
    "mask_config = MaskConfig(**config_data['mask'])\n",
    "data_config = DataConfig(**config_data['data'])\n",
    "trainer_config = TrainerConfig(**config_data['trainer'])\n",
    "\n",
    "config = DiffMaskConfig(\n",
    "    seed=config_data['seed'],\n",
    "    mask=mask_config,\n",
    "    data=data_config,\n",
    "    trainer=trainer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22d1a6-0049-46c6-9c37-9cb71595290a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e5f7a8-c859-4d6f-8ec9-53ad54555e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query batch shape: torch.Size([32, 10])\n",
      "Docs batch shape: torch.Size([32, 10])\n",
      "Reasons batch shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 构造一些示例数据\n",
    "def generate_synthetic_data(num_samples, seq_len):\n",
    "    queries = torch.randint(0, 10000, (num_samples, seq_len))\n",
    "    docs = torch.randint(0, 10000, (num_samples, seq_len))\n",
    "    reasons = torch.randint(0, 10000, (num_samples, seq_len))\n",
    "    return queries, docs, reasons\n",
    "\n",
    "# 生成训练和验证数据\n",
    "num_samples = 1000\n",
    "seq_len = 10\n",
    "\n",
    "queries, docs, reasons = generate_synthetic_data(num_samples, seq_len)\n",
    "\n",
    "# 将数据集划分为训练集和验证集\n",
    "train_size = int(0.8 * num_samples)\n",
    "val_size = num_samples - train_size\n",
    "\n",
    "dataset = TensorDataset(queries, docs, reasons)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 检查数据加载器中的一个批次\n",
    "for batch in train_dataloader:\n",
    "    query_batch, docs_batch, reasons_batch = batch\n",
    "    print(\"Query batch shape:\", query_batch.shape)\n",
    "    print(\"Docs batch shape:\", docs_batch.shape)\n",
    "    print(\"Reasons batch shape:\", reasons_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5737fa87-10a7-44fe-aada-e5b41cf991db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class YourRerankModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(YourRerankModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.query_encoder = nn.Embedding(10000, hidden_dim)\n",
    "        self.doc_encoder = nn.Embedding(10000, hidden_dim)\n",
    "        self.reason_encoder = nn.Embedding(10000, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 3, 1)  # 合并编码器输出后进行全连接层\n",
    "\n",
    "    def forward(self, query, docs, reasons):\n",
    "        # 对 query 进行编码并取平均\n",
    "        query_emb = self.query_encoder(query)  # ([32, 10, 128])\n",
    "        # query_emb = query_emb.mean(dim=0, keepdim=True)  # [1, 10, 128]\n",
    "        query_emb = query_emb.mean(dim=1) \n",
    "        # 对 docs 和 reasons 进行编码并取平均\n",
    "        docs_emb = self.doc_encoder(docs).mean(dim=1)  # [32, 128]\n",
    "        reasons = reasons.long()\n",
    "        reasons_emb = self.reason_encoder(reasons).mean(dim=1)  # [32, 128]\n",
    "\n",
    "        \n",
    "        combined_emb = torch.cat((query_emb, docs_emb, reasons_emb), dim=-1)  # [32, 384]\n",
    "        output = self.fc(combined_emb)  # [32, 1]\n",
    "       \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2687096-f0e8-4eb5-95ae-28ba230b8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "2024-05-26 21:01:35.183168: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-26 21:01:35.228535: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 21:01:35.807146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name         | Type            | Params\n",
      "-------------------------------------------------\n",
      "0 | rerank_model | YourRerankModel | 3.8 M \n",
      "  | other params | n/a             | 17    \n",
      "-------------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.362    Total estimated model params size (MB)\n",
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=79` in the `DataLoader` to improve performance.\n",
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d733d4c704f647c585780657d25ba4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from transformers import get_constant_schedule_with_warmup, get_constant_schedule\n",
    "from distributions import BinaryConcrete, RectifiedStreched\n",
    "# device = \"cuda:0\"\n",
    "class RerankDiffMask(pl.LightningModule):\n",
    "    def __init__(self, config: DiffMaskConfig, rerank_model, device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rerank_model = rerank_model.to(device)\n",
    "        self.lambda1 = torch.nn.Parameter(torch.ones((1,)), requires_grad=True)\n",
    "        self.rerank_model_device = device\n",
    "        num_layers = getattr(rerank_model, 'num_layers', 2)\n",
    "        num_heads = getattr(rerank_model, 'num_heads', 8)\n",
    "        self.location = torch.nn.Parameter(torch.zeros((num_layers, num_heads)), requires_grad=True)\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = [\n",
    "            torch.optim.Adam(\n",
    "                params=[self.location],\n",
    "                lr=self.config.trainer.lr,\n",
    "            ),\n",
    "            torch.optim.Adam(\n",
    "                params=[self.lambda1],\n",
    "                lr=self.config.trainer.lr,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        schedulers = [\n",
    "            get_constant_schedule(optimizers[0]),\n",
    "            get_constant_schedule(optimizers[1]),\n",
    "        ]\n",
    "        return optimizers, schedulers\n",
    "        \n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        optimizer,\n",
    "        optimizer_idx,\n",
    "    ):\n",
    "        if optimizer_idx == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "\n",
    "        elif optimizer_idx == 1:\n",
    "            self.lambda1.grad *= -1\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "\n",
    "            self.lambda1.data = torch.where(\n",
    "                self.lambda1.data < 0,\n",
    "                torch.full_like(self.lambda1.data, 0),\n",
    "                self.lambda1.data,\n",
    "            )\n",
    "            self.lambda1.data = torch.where(\n",
    "                self.lambda1.data > 200,\n",
    "                torch.full_like(self.lambda1.data, 200),\n",
    "                self.lambda1.data,\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        query, docs, reasons = batch\n",
    "        \n",
    "        dist = RectifiedStreched(\n",
    "            BinaryConcrete(torch.full_like(self.location, 0.2), self.location), l=-0.2, r=1.0,\n",
    "        )\n",
    "        # print(\"query shape before\", query.shape) # query shape torch.Size([32, 10])\n",
    "        \n",
    "        mask = dist.rsample(torch.Size([len(query)]))\n",
    "        # print(\"mask shape before\", mask.shape) # mask shape torch.Size([32, 2, 8])\n",
    "        \n",
    "        # mask = mask.mean(dim=1).unsqueeze(1).expand(-1, reasons.size(1), reasons.size(2))  # [32, 10, 10]\n",
    "        mask = mask.view(len(query), -1)[:, :reasons.size(1)]\n",
    "        # print(\"mask shape after\", mask.shape) \n",
    "       \n",
    "        expected_L0 = dist.expected_L0().sum()\n",
    "\n",
    "        # 获取模型输出\n",
    "        original_output = self.rerank_model(query, docs, reasons)\n",
    "      \n",
    "        reasons_mask =  reasons * mask\n",
    "        # print(\"reasons_mask shape\", reasons_mask.shape)\n",
    "        masked_output = self.rerank_model(query, docs, reasons_mask)\n",
    "\n",
    "        # 计算损失\n",
    "        task_loss = self.calculate_task_loss(original_output, masked_output)\n",
    "        kl_loss = torch.distributions.kl_divergence(\n",
    "            torch.distributions.Bernoulli(logits=original_output),\n",
    "            torch.distributions.Bernoulli(logits=masked_output),\n",
    "        ).mean()\n",
    "\n",
    "        total_loss = task_loss + kl_loss + self.lambda1 * (expected_L0 - self.config.mask.attn_heads)\n",
    "\n",
    "        # 反向传播和优化步骤\n",
    "        \n",
    "        self.manual_backward(total_loss)\n",
    "        opt1, opt2= self.optimizers()\n",
    "\n",
    "        self.optimizer_step(opt1, 0)\n",
    "        self.optimizer_step(opt2, 1)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def calculate_task_loss(self, original_output, masked_output):\n",
    "        return torch.nn.functional.mse_loss(original_output, masked_output)\n",
    "\n",
    "# 初始化和训练\n",
    "rerank_model = YourRerankModel()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dm = RerankDiffMask(config=config, rerank_model=rerank_model, device=device)\n",
    "trainer = pl.Trainer(max_epochs=config.trainer.epochs, devices=1, accelerator=\"auto\")\n",
    "trainer.fit(dm, train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78021d0-b411-4b48-9cad-e5b4601a5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = dm.location.detach().cpu().tolist()\n",
    "from pathlib import Path\n",
    "import json\n",
    "def save_json(d, filepath):\n",
    "    \"\"\"Save the dictionary to the given file path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    d : dict\n",
    "        The dictionary to save.\n",
    "    filepath : str\n",
    "        The file path to save the dictionary to.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(d, f)\n",
    "def expected_mask(location):\n",
    "    logits = torch.tensor(location)\n",
    "    dist = RectifiedStreched(BinaryConcrete(torch.full_like(logits, 0.2), logits),\n",
    "                             l=-0.2,\n",
    "                             r=1.0)\n",
    "    return dist.expected_L0().tolist()\n",
    "def results_file(config: DiffMaskConfig):\n",
    "    \"\"\"Get the results file name for the given configuration.\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : DiffMaskConfig\n",
    "        The experiment configuration.\n",
    "    Returns\n",
    "    -------\n",
    "    results_file_name : str\n",
    "        The results file name.\n",
    "    \"\"\"\n",
    "    results_path = Path(config.trainer.results_path)\n",
    "    results_path.mkdir(parents=True, exist_ok=True)\n",
    "    results_file_name = f\"{config.mask.model}\"\n",
    "    results_file_name += f\"_attn_heads_{config.mask.attn_heads}_mlps_{config.mask.mlps}\"\n",
    "    results_file_name += f\"_epochs_{config.trainer.epochs}_lr_{config.trainer.lr}_seed_{config.seed}.json\"\n",
    "    return results_path.joinpath(results_file_name)\n",
    "save_json({\"location\": location, \"mask\": expected_mask(location=location)}, results_file(config))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fe007-5a07-4f0a-a44c-d0fd9176d528",
   "metadata": {},
   "source": [
    "## Add attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef60dafe-f29b-494c-b2a6-0142078791ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from functools import partial\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, ActivationCache\n",
    "from transformer_lens.hook_points import HookPoint  \n",
    "from distributions import BinaryConcrete, RectifiedStreched\n",
    "# from configuration.diffmask import DiffMaskConfig\n",
    "from transformers import get_constant_schedule_with_warmup, get_constant_schedule\n",
    "\n",
    "def attention_intervention_hook(\n",
    "    value: torch.Tensor,\n",
    "    hook: HookPoint,\n",
    "    counterfactual_cache: ActivationCache,\n",
    "    mask: torch.Tensor,\n",
    "    tail_indices: torch.Tensor,\n",
    "    cf_tail_indices: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    b, p, h, d = value.shape\n",
    "    \n",
    "    # 确保 tail_indices 和 cf_tail_indices 的维度与 value 一致\n",
    "    tail_indices = tail_indices.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(-1, -1, h, d)\n",
    "    cf_tail_indices = cf_tail_indices.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(-1, -1, h, d)\n",
    "    \n",
    "    counterfactual_value = counterfactual_cache[hook.name]\n",
    "\n",
    "    # 获取对应位置的值\n",
    "    v_select = torch.gather(value, 1, tail_indices)\n",
    "    cf_select = torch.gather(counterfactual_value, 1, cf_tail_indices)\n",
    "    # print(\"v_select shape:\", v_select.shape)\n",
    "    # print(\"cf_select shape:\", cf_select.shape)\n",
    "    # print(\"mask shape:\", mask.shape)\n",
    "\n",
    "    # 计算需要的重复次数\n",
    "    repeat_times = 768 // 8  # 这里我们重复 96 次（768 // 8）\n",
    "    \n",
    "    # 使用 repeat 扩展 mask\n",
    "    mask = mask.repeat(1, 1, 1, repeat_times)  # 扩展到 [32, 12, 2, 768]\n",
    "    \n",
    "    # 使用 reshape 调整 mask 形状\n",
    "    mask = mask.reshape(32, 12, -1)  # 调整为 [32, 12, 1536]\n",
    "    \n",
    "    # 在第一个维度增加一个维度\n",
    "    mask = mask.unsqueeze(1)  # 调整为 [32, 1, 12, 1536]\n",
    "    \n",
    "    # 将 mask 截取为 [32, 1, 12, 768] 的目标维度\n",
    "    mask = mask[:, :, :, :768]  # 调整为目标维度 [32, 1, 12, 768]\n",
    "     \n",
    "    # 根据 mask 进行介入\n",
    "    intervention = (1 - mask) * v_select + mask * cf_select\n",
    "    return torch.scatter(value, dim=1, index=tail_indices, src=intervention)\n",
    "\n",
    "class AttentionRerankDiffMask(pl.LightningModule):\n",
    "    def __init__(self, config: DiffMaskConfig, rerank_model, device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rerank_model = rerank_model.to(device)\n",
    "        self.lambda1 = torch.nn.Parameter(torch.ones((1,)), requires_grad=True)\n",
    "        self.attention_device = device\n",
    "        num_layers = getattr(rerank_model, 'num_layers', 2)\n",
    "        num_heads = getattr(rerank_model, 'num_heads', 8)\n",
    "        self.location = torch.nn.Parameter(torch.zeros((num_layers, num_heads)), requires_grad=True)\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        # Initialize the transformer model with attention\n",
    "        self.model = HookedTransformer.from_pretrained(config.mask.model, device=device)\n",
    "        self.model.cfg.use_attn_result = True\n",
    "        self.she_token = self.model.tokenizer.encode(' she')[0]\n",
    "        self.he_token = self.model.tokenizer.encode(' he')[0]\n",
    "        self.attention_weights = []  # 用于存储注意力权重\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = [\n",
    "            torch.optim.Adam(params=[self.location], lr=self.config.trainer.lr),\n",
    "            torch.optim.Adam(params=[self.lambda1], lr=self.config.trainer.lr),\n",
    "        ]\n",
    "        schedulers = [\n",
    "            get_constant_schedule(optimizers[0]),\n",
    "            get_constant_schedule(optimizers[1]),\n",
    "        ]\n",
    "        return optimizers, schedulers\n",
    "\n",
    "    def optimizer_step(self, optimizer, optimizer_idx):\n",
    "        if optimizer_idx == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "        elif optimizer_idx == 1:\n",
    "            self.lambda1.grad *= -1\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "            self.lambda1.data = torch.clamp(self.lambda1.data, 0, 200)\n",
    "\n",
    "    def intervene(self, query, docs, reasons, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: 原始查询序列\n",
    "            docs: 原始文档序列\n",
    "            reasons: 原始原因序列\n",
    "            mask: 介入的掩码\n",
    "        Returns:\n",
    "            o_logits: 原始 logits\n",
    "            i_logits: 介入后的 logits\n",
    "        \"\"\"\n",
    "        # 获取反事实输入的 tokens\n",
    "        cf_tokens = self.model.to_tokens([self.model.tokenizer.decode(doc) for doc in docs])\n",
    "        cf_logits, counterfactual_cache = self.model.run_with_cache(cf_tokens)\n",
    "        cf_tail_indices = self._tail_indices(cf_tokens, self.model.tokenizer.eos_token_id) \n",
    "        \n",
    "        # 获取原始输入的 tokens\n",
    "        o_tokens = self.model.to_tokens([self.model.tokenizer.decode(query) for query in query])\n",
    "        tail_indices = self._tail_indices(o_tokens, self.model.tokenizer.eos_token_id)\n",
    "        o_logits = self.model(o_tokens, return_type=\"logits\") \n",
    "\n",
    "\n",
    "        self.attention_weights = []  # 清空之前的注意力权重\n",
    "        def hook_fn(module, input, output):\n",
    "            self.attention_weights.append(output.detach().cpu())\n",
    "        \n",
    "        hooks = []\n",
    "        for i in range(self.model.cfg.n_layers):\n",
    "            hook = self.model.blocks[i].attn.hook_result.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "\n",
    "        \n",
    "        # 通过 hooks 在注意力结果上进行介入\n",
    "        i_logits = self.model.run_with_hooks(\n",
    "            o_tokens,\n",
    "            return_type=\"logits\",\n",
    "            fwd_hooks=[(f\"blocks.{i}.attn.hook_result\",\n",
    "                        partial(attention_intervention_hook,\n",
    "                                counterfactual_cache=counterfactual_cache,\n",
    "                                mask=mask[:, i, :],\n",
    "                                tail_indices=tail_indices,\n",
    "                                cf_tail_indices=cf_tail_indices)\n",
    "                                )\n",
    "                        for i in range(self.model.cfg.n_layers)],\n",
    "        )\n",
    "\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        # 只选择最后一个位置的 logits\n",
    "        tail_indices = tail_indices.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, o_logits.shape[2])\n",
    "        o_logits = torch.gather(o_logits, 1, tail_indices).squeeze()\n",
    "        i_logits = torch.gather(i_logits, 1, tail_indices).squeeze()\n",
    "        \n",
    "        return o_logits, i_logits\n",
    "    \n",
    "    def _tail_indices(self, tokens, eos_token_id):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tokens: A batch of token sequences.\n",
    "            eos_token_id: The id of the end-of-sequence token.\n",
    "        Returns:\n",
    "            The index of the last true token in each sequence.\n",
    "        \"\"\"\n",
    "        _, length = tokens.shape\n",
    "        eos_mask = torch.where(tokens == eos_token_id, 1.0, 0.0)\n",
    "        tail_indices = torch.argmax(eos_mask[:, 1:], dim=1)\n",
    "        tail_indices = torch.where(tail_indices == 0, length - 1, tail_indices)\n",
    "        return tail_indices\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        query, docs, reasons = batch\n",
    "\n",
    "        dist = RectifiedStreched(\n",
    "            BinaryConcrete(torch.full_like(self.location, 0.2), self.location), l=-0.2, r=1.0,\n",
    "        )\n",
    "        mask = dist.rsample(torch.Size([len(query), self.model.cfg.n_layers, self.model.cfg.n_heads]))\n",
    "        \n",
    "        expected_L0 = dist.expected_L0().sum()\n",
    "\n",
    "        # 获取模型输出\n",
    "        original_output = self.rerank_model(query, docs, reasons)\n",
    "        reasons_masked = reasons * mask[:, 0, :].view(len(query), -1)[:, :reasons.size(1)]\n",
    "        masked_output = self.rerank_model(query, docs, reasons_masked)\n",
    "\n",
    "        # Intervene using attention mechanism\n",
    "        o_logits, i_logits = self.intervene(query, docs, reasons, mask=mask)\n",
    "        o_probs = torch.softmax(o_logits, dim=-1)\n",
    "        i_probs = torch.softmax(i_logits, dim=-1)\n",
    "\n",
    "        o_probs_he = o_probs[:, self.he_token].squeeze()\n",
    "        o_probs_she = o_probs[:, self.she_token].squeeze()\n",
    "        i_probs_he = i_probs[:, self.he_token].squeeze()\n",
    "        i_probs_she = i_probs[:, self.she_token].squeeze()\n",
    "\n",
    "        y = torch.argmax(reasons, dim=1)\n",
    "        o_probs = torch.where(y == 1, o_probs_he, o_probs_she)\n",
    "        i_probs = torch.where(y == 1, i_probs_she, i_probs_he)\n",
    "\n",
    "        loss_r = o_probs / i_probs\n",
    "        loss_r = loss_r.mean()\n",
    "\n",
    "        kl_loss = torch.distributions.kl_divergence(\n",
    "            torch.distributions.Bernoulli(logits=original_output),\n",
    "            torch.distributions.Bernoulli(logits=masked_output),\n",
    "        ).mean()\n",
    "\n",
    "        total_loss = loss_r + kl_loss + self.lambda1 * (expected_L0 - self.config.mask.attn_heads)\n",
    "\n",
    "        self.manual_backward(total_loss)\n",
    "        opt1, opt2 = self.optimizers()\n",
    "        self.optimizer_step(opt1, 0)\n",
    "        self.optimizer_step(opt2, 1)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def calculate_task_loss(self, original_output, masked_output):\n",
    "        return torch.nn.functional.mse_loss(original_output, masked_output)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        print(f\"lambda1: {self.lambda1}\")\n",
    "        print(f\"location: {self.location}\")\n",
    "\n",
    "# # 使用第二块 GPU\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# rerank_model = YourRerankModel()\n",
    "# dm = AttentionRerankDiffMask(config=config, rerank_model=rerank_model, device=device)\n",
    "# trainer = pl.Trainer(max_epochs=config.trainer.epochs, devices=1, accelerator=\"gpu\")\n",
    "# trainer.fit(dm, train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ee219-6c63-4964-a96c-818c0ae385fd",
   "metadata": {},
   "source": [
    "## Visual Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4db115e-bffe-4299-95aa-6ea31ebe22f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.8/site-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# from diffmask import DiffMaskConfig \n",
    "\n",
    "from transformers import get_constant_schedule_with_warmup, get_constant_schedule\n",
    "\n",
    "\n",
    "class DiffMask(pl.LightningModule):\n",
    "    def __init__(self, config: DiffMaskConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.lambda1 = torch.nn.Parameter(torch.ones((1,)), requires_grad=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = [\n",
    "            torch.optim.Adam(\n",
    "                params=[self.location],\n",
    "                lr=self.config.trainer.lr,\n",
    "            ),\n",
    "            torch.optim.Adam(\n",
    "                params=[self.lambda1],\n",
    "                lr=self.config.trainer.lr,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        schedulers = [\n",
    "            get_constant_schedule(optimizers[0]),\n",
    "            get_constant_schedule(optimizers[1]),\n",
    "        ]\n",
    "        return optimizers, schedulers\n",
    "\n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        optimizer,\n",
    "        optimizer_idx,\n",
    "    ):\n",
    "        if optimizer_idx == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "\n",
    "        elif optimizer_idx == 1:\n",
    "            self.lambda1.grad *= -1\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            for g in optimizer.param_groups:\n",
    "                for p in g[\"params\"]:\n",
    "                    p.grad = None\n",
    "\n",
    "            self.lambda1.data = torch.where(\n",
    "                self.lambda1.data < 0,\n",
    "                torch.full_like(self.lambda1.data, 0),\n",
    "                self.lambda1.data,\n",
    "            )\n",
    "            self.lambda1.data = torch.where(\n",
    "                self.lambda1.data > 200,\n",
    "                torch.full_like(self.lambda1.data, 200),\n",
    "                self.lambda1.data,\n",
    "            )\n",
    "\n",
    "@torch.distributions.kl.register_kl(\n",
    "    torch.distributions.Bernoulli, torch.distributions.Bernoulli\n",
    ")\n",
    "def kl_bernoulli_bernoulli(p, q):\n",
    "    t1 = p.probs * (torch.log(p.probs + 1e-5) - torch.log(q.probs + 1e-5))\n",
    "    t2 = (1 - p.probs) * (torch.log1p(-p.probs + 1e-5) - torch.log1p(-q.probs + 1e-5))\n",
    "    return t1 + t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a9bc052-b7e4-4629-af53-a95b795bdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.hook_points import HookedRootModule, HookPoint  \n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import lightning.pytorch as pl\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from typing import List\n",
    "from jaxtyping import Float, Int\n",
    "def attention_intervention_hook(\n",
    "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
    "    hook: HookPoint,\n",
    "    counterfactual_cache: ActivationCache,\n",
    "    mask: torch.Tensor,\n",
    "    tail_indices: torch.Tensor,\n",
    "    cf_tail_indices: torch.Tensor,\n",
    ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        value: The attention result.\n",
    "        hook: The hook point.\n",
    "        counterfactual_cache: The counterfactual cache.\n",
    "        mask: The mask.\n",
    "        end_indices: The end indices of the sequences.\n",
    "    Returns:\n",
    "        The intervened attention result.\n",
    "    \"\"\"\n",
    "    b, p, h, d = value.shape\n",
    "    device = value.device\n",
    "    tail_indices = tail_indices.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).repeat(1, 1, h, d) \n",
    "    cf_tail_indices = cf_tail_indices.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).repeat(1, 1, h, d)\n",
    "    counterfactual_value = counterfactual_cache[hook.name]\n",
    "    tail_indices = tail_indices.to(device)\n",
    "    cf_tail_indices = cf_tail_indices.to(device)\n",
    "    \n",
    "    \n",
    "    v_select = torch.gather(value, 1, tail_indices)\n",
    "    cf_select = torch.gather(counterfactual_value, 1, cf_tail_indices)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(-1).repeat(1, 1, 1, d)\n",
    "    counterfactual_cache = counterfactual_cache.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    intervention = (1-mask) * v_select + mask * cf_select\n",
    "    return torch.scatter(value, dim=1, index=tail_indices, src=intervention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17d03705-a19a-41d8-8798-f58de1b4b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionDiffMask(DiffMask):\n",
    "    def __init__(self, config: DiffMaskConfig, device):\n",
    "        super().__init__(config=config)\n",
    "        self.config = config\n",
    "        self.automatic_optimization = False\n",
    "        self.model = HookedTransformer.from_pretrained(config.mask.model, device=device)\n",
    "        self.model.cfg.use_attn_result = True\n",
    "        self.location = torch.nn.Parameter(torch.zeros((self.model.cfg.n_layers, self.model.cfg.n_heads)), requires_grad=True)\n",
    "        self.she_token = self.model.tokenizer.encode(' she')[0]\n",
    "        self.he_token = self.model.tokenizer.encode(' he')[0]\n",
    "        self.attention_weights = []  # 用于存储注意力权重\n",
    "    def _tail_indices(self, tokens, eos_token_id):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tokens: A batch of token sequences.\n",
    "            eos_token_id: The id of the end-of-sequence token.\n",
    "        Returns:\n",
    "            The index of the last true token in each sequence.\n",
    "        \"\"\"\n",
    "        _, length = tokens.shape\n",
    "        eos_mask = torch.where(tokens == eos_token_id, 1.0, 0.0)\n",
    "        tail_indices = torch.argmax(eos_mask[:, 1:], dim=1)\n",
    "        tail_indices = torch.where(tail_indices == 0, length - 1, tail_indices)\n",
    "        return tail_indices\n",
    "    \n",
    "    def intervene(self, originals, counterfactuals, mask):\n",
    "        cf_tokens = self.model.to_tokens(counterfactuals)\n",
    "        cf_logits, counterfactual_cache = self.model.run_with_cache(cf_tokens)\n",
    "        cf_tail_indices = self._tail_indices(cf_tokens, self.model.tokenizer.eos_token_id) \n",
    "        \n",
    "        o_tokens = self.model.to_tokens(originals)\n",
    "        tail_indices = self._tail_indices(o_tokens, self.model.tokenizer.eos_token_id)\n",
    "        o_logits = self.model(o_tokens, return_type=\"logits\") \n",
    "        \n",
    "        self.attention_weights = []  # 清空之前的注意力权重\n",
    "        def hook_fn(module, input, output):\n",
    "            self.attention_weights.append(output.detach().cpu())\n",
    "        \n",
    "        hooks = []\n",
    "        for i in range(self.model.cfg.n_layers):\n",
    "            hook = self.model.blocks[i].attn.hook_result.register_forward_hook(hook_fn)\n",
    "            hooks.append(hook)\n",
    "        \n",
    "        i_logits = self.model.run_with_hooks(\n",
    "            o_tokens,\n",
    "            return_type=\"logits\",\n",
    "            fwd_hooks=[(f\"blocks.{i}.attn.hook_result\",\n",
    "                        partial(attention_intervention_hook,\n",
    "                                counterfactual_cache=counterfactual_cache,\n",
    "                                mask=mask[:, i, :].squeeze(),\n",
    "                                tail_indices=tail_indices,\n",
    "                                cf_tail_indices=cf_tail_indices)\n",
    "                        )\n",
    "                        for i in range(self.model.cfg.n_layers)],\n",
    "        )\n",
    "        \n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        tail_indices = tail_indices.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, o_logits.shape[2])\n",
    "        o_logits = torch.gather(o_logits, 1, tail_indices).squeeze()\n",
    "        i_logits = torch.gather(i_logits, 1, tail_indices).squeeze()\n",
    "        return o_logits, i_logits\n",
    "        \n",
    "    def training_step(self, batch, batch_idx=None, optimizer_idx=None):\n",
    "        originals, counterfactuals, y = batch\n",
    "        dist = RectifiedStreched(\n",
    "            BinaryConcrete(torch.full_like(self.location, 0.2), self.location), l=-0.2, r=1.0,\n",
    "        )\n",
    "        mask = dist.rsample(torch.Size([len(originals)]))\n",
    "        expected_L0 = dist.expected_L0().sum()\n",
    "\n",
    "        o_logits, i_logits = self.intervene(originals, counterfactuals, mask=mask)\n",
    "        o_probs = torch.softmax(o_logits, dim=-1)\n",
    "        i_probs = torch.softmax(i_logits, dim=-1)\n",
    "\n",
    "        o_probs_he = o_probs[:,self.he_token].squeeze()\n",
    "        o_probs_she = o_probs[:,self.she_token].squeeze()\n",
    "        i_probs_he = i_probs[:,self.he_token].squeeze()\n",
    "        i_probs_she = i_probs[:,self.she_token].squeeze()\n",
    "\n",
    "        o_probs = torch.where(y == 1, o_probs_he, o_probs_she)\n",
    "        i_probs = torch.where(y == 1, i_probs_she, i_probs_he)\n",
    "        \n",
    "        loss_r = o_probs/i_probs\n",
    "        loss_r = loss_r.mean()\n",
    "\n",
    "        loss_c = torch.distributions.kl_divergence(\n",
    "                torch.distributions.Bernoulli(logits=o_logits),\n",
    "                torch.distributions.Bernoulli(logits=i_logits),\n",
    "            ).mean()\n",
    "        loss = loss_c + loss_r +  self.lambda1 * (expected_L0 - self.config.mask.attn_heads)\n",
    "       \n",
    "        o1, o2 = self.optimizers()\n",
    "        self.manual_backward(loss)\n",
    "        self.optimizer_step(o1, 0)\n",
    "        self.optimizer_step(o2, 1)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        print(f\"lambda1: {self.lambda1}\")\n",
    "        print(f\"location: {self.location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e28199b1-6de4-449a-922f-f8c425db1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_attention(attention_weights, layer, head, sentence, tokens):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    attention = attention_weights[layer][0, head, :, :].numpy()  # 选择特定层和头的注意力权重\n",
    "    sns.heatmap(attention, xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "    plt.title(f'Attention weights for layer {layer}, head {head}')\n",
    "    plt.xlabel('Tokens')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc6c5811-8a29-48e4-8e9b-8ad3f26c3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the device to use.\n",
    "    Returns\n",
    "    -------\n",
    "    device : torch.device\n",
    "        The device to use.\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af1737f-d545-4334-99b1-d83b70d96b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0AAAAN/CAYAAAD3T7g6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAACEQUlEQVR4nOzdd5xU5d3///c1dQuwwCJNaYJYEMWIFTV4C8GIWJKYW83PWFIsGIzta3gYE40FjaYYjDUqlmhIUW5jC1hjbvWOGrEC9pIAonS2zO7MuX5/nDq7i2En24bzej4e89iZM+dc1+cq58xee117xlhrrQAAAAAgBhLdHQAAAAAAdBUGQAAAAABigwEQAAAAgNhgAAQAAAAgNhgAAQAAAIgNBkAAAAAAYoMBEAAAAIDYYAAEAAAAIDYYAAEAAACIDQZAQEz96le/kjFGu+66a5vvv/nmm7r44ov1wQcftHrvnnvu0S9/+cvODXAL4jjppJM0cuTILomjK33wwQcyxmjevHklHW+M0Zlnnvlv93v22Wd18cUXa926dSXl05ampiaddtppGjJkiJLJpCZMmNBhabel3PvApk2b9P3vf19Dhw5VRUWFJkyYoN/97nclp/fUU0/JGKM//vGPHRjlf8aP6amnnvq3+3Z0fQBAWxgAATF12223SZLeeOMN/d///V+r9998801dcsklPWIAtLk4LrroIt1///1dEkdXGjJkiJ577jlNnz69U/N59tlndckll3ToAOiGG27QTTfdpAsvvFB/+9vfdNddd3VY2lujr3zlK7rjjjv04x//WI888oj22msvHXfccbrnnnu6O7RuQX0A6Aqp7g4AQNd78cUX9corr2j69Ol66KGHdOutt2qfffbp7rDabfTo0d0dQqfIZrPad999uzuMkrz++uuqrKzcohmoLdXQ0KDKysoOS68r1dfXq6qqqs33Hn74YS1atEj33HOPjjvuOEnSwQcfrA8//FDnn3++/vu//1vJZLIrw+1W1AeArsIMEBBDt956qyTpyiuv1P7776/f/e53qq+vD96fN2+ejjnmGEnuLyDGmGBJ1uTJk/XQQw/pww8/DLYbY4Jjm5qadNlll2mnnXZSNpvVNttso5NPPlmffvppUQwjR47U4YcfrkcffVRf+MIXVFlZqZ122imYmfp3cUhtL39qbGzU7NmzNWrUKGUyGW277baaOXNmq1mOLcl/c/baa69WszPjx4+XMUYvvPBCsO2+++6TMUavvfZasO3tt9/W8ccfr4EDByqbzWrnnXfWr3/966K0NrcE7n/+53+02267KZvNavvtt9e1116riy++uKj+o+666y7tvPPOqqqq0u67764HH3wweO/iiy/W+eefL0kaNWpUULf+MqUnnnhCkydPVm1trSorKzV8+HB99atfLeonLRlj9Jvf/EYNDQ2t2qq97XLfffdpjz32UEVFhS655JLN5tmWX//61zrooIM0cOBAVVdXa/z48frpT3+q5ubmYJ9LL71UqVRKH3/8cavjTznlFNXW1qqxsTHYNn/+fO23336qrq5Wr169NG3aNL388stFx5100knq1auXXnvtNX3pS19S7969dcghh2w2zvvvv1+9evUK+rjv5JNP1vLly9ucmd1Szc3NuvDCCzV06FD16dNHU6ZM0bJly1rt99hjj+mQQw5Rnz59VFVVpUmTJunxxx8v2uedd97RySefrB122EFVVVXadtttNWPGjKJ+7Vu6dKkOPfRQVVVVacCAATrttNO0cePGLYq5M+sDAIpYALFSX19va2pq7F577WWttfY3v/mNlWTnzZsX7LNq1Sp7xRVXWEn217/+tX3uuefsc889Z1etWmXfeOMNO2nSJDt48OBg+3PPPWettbZQKNhDDz3UVldX20suucQuWrTI/uY3v7Hbbrut3WWXXWx9fX2Qx4gRI+x2221nd9llF3vnnXfav/zlL/aYY46xkuzTTz/9b+Ow1toTTzzRjhgxIkjTcRw7bdo0m0ql7EUXXWQXLlxor7nmGltdXW332GMP29jY2K78N+cHP/iB7dWrl21qarLWWrty5UoryVZWVtrLL7882O/000+3gwYNCl6/8cYbtqamxo4fP97eeeedduHChfbcc8+1iUTCXnzxxcF+77//vpVkb7/99mDbI488YhOJhJ08ebK9//777R/+8Ae7zz772JEjR9qWl3JJduTIkXbvvfe2v//97+3DDz9sJ0+ebFOplH333XettdZ+/PHH9nvf+56VZO+7776gbtevX2/ff/99W1FRYadOnWoXLFhgn3rqKfvb3/7WnnDCCXbt2rWbrZfnnnvOHnbYYbaysrKordrbLkOGDLHbb7+9ve222+yTTz5p//73v282z5Z9wFprzz77bHvDDTfYRx991D7xxBP2F7/4hR0wYIA9+eSTg30++eQTm81m7YUXXlh07OrVq21lZaU9//zzg22XX365NcbYU045xT744IP2vvvus/vtt5+trq62b7zxRlEs6XTajhw50s6ZM8c+/vjj9i9/+ctmY993332D8zDq9ddft5LsTTfdtNljN+fJJ58M2v8b3/iGfeihh+y9995rhw8fbnfYYQebz+eDfe+66y5rjLFHHXWUve++++yf//xne/jhh9tkMmkfe+yxYL+nn37annvuufaPf/yjffrpp+39999vjzrqKFtZWWmXLl0a7Ldy5Uo7cOBAu+2229rbb7/dPvzww/Yb3/iGHT58uJVkn3zyyc+NvTPqAwDawgAIiJk777zTSrI33nijtdbajRs32l69etkDDzywaL8//OEPm/2lZfr06a1+6bTW2nvvvddKsn/605+Ktr/wwgtWkr3++uuDbSNGjLAVFRX2ww8/DLY1NDTY/v3721NPPXWL4mj5y++jjz5qJdmf/vSnRfvNnz/fSrI333xzu/Nvy2OPPWYl2b/+9a/WWmvvvvtu27t3b3vGGWfYgw8+ONhvhx12sMcff3zwetq0aXa77baz69evL0rvzDPPtBUVFXbNmjXW2rYHQHvttZcdNmyYzeVywbaNGzfa2traNgdAgwYNshs2bAi2rVy50iYSCTtnzpxg29VXX20l2ffff7/o+D/+8Y9Wkl28ePHn1kNbTjzxRFtdXV20rb3tkkwm7bJly7Y4v7b6oq9QKNjm5mZ755132mQyGdSxf+zAgQOL6vSqq66yiUQiqJOPPvrIplIp+73vfa8o3Y0bN9rBgwfbr3/960XpSbK33XbbFsW+ww472GnTprXavnz5civJXnHFFVuUTpQ/ADrssMOKtv/+97+3koI/VtTV1dn+/fvbGTNmFO1XKBTs7rvvbvfee+/N5pHP521TU5PdYYcd7Nlnnx1sv+CCC6wxplW/mTp16hYNgDqjPgCgLSyBA2Lm1ltvVWVlpY499lhJCpacPPPMM3r77bf/o7QffPBB9e3bVzNmzFA+nw8eEyZM0ODBg1vdBWrChAkaPnx48LqiokJjx47Vhx9+WFL+TzzxhCR3KVLUMccco+rq6lZLe0rNf9KkSaqoqNBjjz0mSVq0aJEmT56sQw89VM8++6zq6+v18ccf6+2339aUKVMkuUvAHn/8cR199NGqqqoqqp/DDjtMjY2Nev7559vMr66uTi+++KKOOuooZTKZYHuvXr00Y8aMNo85+OCD1bt37+D1oEGDNHDgwC2q2wkTJiiTyei73/2u7rjjDr333nv/9pjP09522W233TR27NiS83v55Zd1xBFHqLa2VslkUul0Wt/85jdVKBT01ltvBfudddZZWrVqlf7whz9IkhzH0Q033KDp06cHSyv/8pe/KJ/P65vf/GZRm1VUVOiLX/xim3c2++pXv7rFsW5u+eK/e+/fOeKII4pe77bbbpIUtP+zzz6rNWvW6MQTTywql+M4OvTQQ/XCCy+orq5OkpTP53XFFVdol112USaTUSqVUiaT0dtvv60lS5YEeTz55JMaN26cdt9996K8jz/++C2Ou7PqAwCiGAABMfLOO+/or3/9q6ZPny5rrdatW6d169bpa1/7miRt0f+/fJ5PPvlE69atUyaTUTqdLnqsXLlSn332WdH+tbW1rdLIZrNqaGgoKf/Vq1crlUppm222KdpujNHgwYO1evXqDsm/oqJCkyZNCgZAjz/+uKZOnarJkyerUCjomWee0aJFiyQpGACtXr1a+Xxec+fObVU3hx12mCS1qh/f2rVrZa3VoEGDWr3X1rb/pGySe3OJxx57TAMHDtTMmTM1evRojR49Wtdee+2/PbYt7W2XIUOGlJSPJH300Uc68MAD9a9//UvXXnutnnnmGb3wwgvB/1lFy7/HHnvowAMPDN578MEH9cEHHxTdwOGTTz6R5P7fV8t2mz9/fqs2q6qqUp8+fbYo1tra2lZll6Q1a9ZIkvr379+OkrdOOyqbzUoKy++X62tf+1qrcl111VWy1gZxnHPOObrooot01FFH6c9//rP+7//+Ty+88IJ23333ovpcvXq1Bg8e3CqWtrZtLubOqg8AiOIucECM3HbbbbLW6o9//GOb3xNyxx136LLLLiv5TksDBgxQbW2tHn300Tbfj85IdIba2lrl83l9+umnRb9sW2u1cuVK7bXXXh2W1yGHHKIf/ehH+vvf/65//vOfmjp1qnr37q299tpLixYt0vLlyzV27FgNGzZMktSvXz8lk0mdcMIJmjlzZptpjho1qs3t/fr1kzEm+KU1auXKlR1WpqgDDzxQBx54oAqFgl588UXNnTtX3//+9zVo0KBg9nBLtbdd/pO/9C9YsEB1dXW67777NGLEiGD74sWL29x/1qxZOuaYY/SPf/xD1113ncaOHaupU6cG7w8YMECS9Mc//rEovc1pT+zjx4/Xvffeq3w+r1Qq/Dj2by6wue/o6gh+uebOnbvZOw76g+u7775b3/zmN3XFFVcUvf/ZZ5+pb9++weva2to2++OW9tHurA8A8cIMEBAThUJBd9xxh0aPHq0nn3yy1ePcc8/VihUr9Mgjj0hq/RfjqM3NJBx++OFavXq1CoWCJk6c2Oqx4447tjvuz4ujJf+OW3fffXfR9j/96U+qq6v73DtytdeUKVOUz+d10UUXabvtttNOO+0UbH/sscf0xBNPBLM/kjszcPDBB+vll1/Wbrvt1mb9tDVrI0nV1dWaOHGiFixYoKampmD7pk2biu7s1l5bUrfJZFL77LNPMEvyj3/8o935dGW7+AMQv2ySO9C65ZZb2tz/6KOP1vDhw3Xuuefqscce0xlnnFE0iJk2bZpSqZTefffdNtts4sSJJcd69NFHa9OmTfrTn/5UtP2OO+7Q0KFDO/XW9JMmTVLfvn315ptvbrZc/nJLY0xRfUrSQw89pH/9619F2w4++GC98cYbeuWVV4q2b+l3+HRnfQCIF2aAgJh45JFHtHz5cl111VWaPHlyq/d33XVXXXfddbr11lt1+OGHB39tvfnmm9W7d29VVFRo1KhRqq2t1fjx43Xffffphhtu0J577qlEIqGJEyfq2GOP1W9/+1sddthhOuuss7T33nsrnU7rn//8p5588kkdeeSROvroo9sV9+fF0dLUqVM1bdo0XXDBBdqwYYMmTZqkV199VT/+8Y+1xx576IQTTmh/xW3GnnvuqX79+mnhwoU6+eSTg+1TpkzRpZdeGjyPuvbaa3XAAQfowAMP1Omnn66RI0dq48aNeuedd/TnP/85+F+ZtvzkJz/R9OnTNW3aNJ111lkqFAq6+uqr1atXr2CJUHuNHz8+iOvEE09UOp3WjjvuqN/+9rd64oknNH36dA0fPlyNjY3B8siWZdoSXdkuU6dOVSaT0XHHHaf/9//+nxobG3XDDTdo7dq1be6fTCY1c+ZMXXDBBaqurm71f0ojR47UT37yE1144YV67733dOihh6pfv3765JNP9Pe//13V1dXtvk2378tf/rKmTp2q008/XRs2bNCYMWN077336tFHH9Xdd99dNBM7b948nXzyybr99ttbxViKXr16ae7cuTrxxBO1Zs0afe1rX9PAgQP16aef6pVXXtGnn36qG264QZL7h4158+Zpp5120m677aaXXnpJV199tbbbbruiNL///e/rtttu0/Tp03XZZZdp0KBB+u1vf6ulS5d2eH0AwH+kG2/AAKALHXXUUTaTyQS3kG7Lsccea1OplF25cqW11tpf/vKXdtSoUTaZTBbdlWzNmjX2a1/7mu3bt681xhTdhay5udlec801dvfdd7cVFRW2V69edqeddrKnnnqqffvtt4P9RowYYadPn94qhi9+8Yv2i1/8YtG2zcXR1h3AGhoa7AUXXGBHjBhh0+m0HTJkiD399NNb3b65PflvztFHH20l2d/+9rfBtqamJltdXW0TiUSbt4x+//337SmnnGK33XZbm06n7TbbbGP3339/e9lllxXtoxZ3gbPW2vvvv9+OHz/eZjIZO3z4cHvllVfaWbNm2X79+hXtJ8nOnDmzVd4jRoywJ554YtG22bNn26FDh9pEIhHcqeu5556zRx99tB0xYoTNZrO2trbWfvGLX7QPPPDAv62Ttu4CZ+1/3i6fl1/LPvDnP/856H/bbrutPf/88+0jjzyy2TuRffDBB1aSPe200zabz4IFC+zBBx9s+/TpY7PZrB0xYoT92te+VnS76M2V/fNs3LjRzpo1yw4ePNhmMhm722672XvvvbfVfnPnzrWS7KOPPvq56fl3gfvDH/5QtH1zferpp5+206dPt/3797fpdNpuu+22dvr06UXHr1271n7rW9+yAwcOtFVVVfaAAw6wzzzzTJvnyptvvmmnTp1qKyoqbP/+/e23vvUt+z//8z9bdBe49tQHAPwnjLXWdsvICwDwH2lubtaECRO07bbbauHChd0dTtmaO3euZs2apddff13jxo3r7nDa9PWvf13vv/9+0RftAgBKwxI4ACgT3/rWtzR16lQNGTJEK1eu1I033qglS5aUfHe2uHv55Zf1/vvv6yc/+YmOPPLIHjv4sdbqqaeeavU/VACA0jAAAoAysXHjRp133nn69NNPlU6n9YUvfEEPP/xwSf+XA/ef7leuXKkDDzxQN954Y3eHs1nGGK1ataq7wwCArQZL4AAAAADEBrfBBgAAABAbDIAAAAAAxAYDIAAAAACxwQAIAAAAQGxwF7huNO4Hv1CiSSpUSMZKTkpK5KVETrIpyXpfem2N5KSldJ1UyEpqcduKRN7b10rWH9KacD9j3feTjVIhEzkwso9NSqbgPk/6MRXcvIPd/X2NG1+iOcwvX+nGZ42bj5N1tyUbIzEk3DImG714vfyN4z4vZKRkzkszIclpXWfGFsck48Xplb+o3E6kPrxj85VSqk5yMu5xft7WRI41btkc7+xI5tz6kA3bSQrrKyhHpA2DfK2bl6ybZhB/5Bhrisvl1190u5+mkw7LG83f5N02idZB0F6JcHsyF+kDft0lvGMU1l3L+nYybvybe9+vD7/PFm23YQzJJjf/aNvYlBt/mzH4ZfP6i016+0aOa9nO/p91Ek1ee9e79ZZodn9G+0hROZLuMTbpple9wqqh1rjHbIafdxBDJO1Es1tvqQY3DuO0cT7ZsO/6dVOxVmrsF2njNuLdXP1Hy++Ltn9b6aTrpObq1n2zpaYaKbPefZ5qcM+JIG0v30RTeG7ZRHF7FaXb8vpkwjZqq2xF5UlGzgHvGuH362hf8+skuNaouB6i1zNJSjVK+Qr3feNI2TVSY21x3i2P8feV4/VHJ3w/iEWRto+e95E4nax73Y+ek0XXk821S4ttibzXx9vqL9Frasu02miPRLMbV8vrsLFhW7Vqnzauv04mPK9aXjP9dml5biTy3nXT8Y5JuO3r94/gnGrRR1qeh9FzOsgz0fqzrWUZguuiItcNhe0vuekWst72QvH1N5lr47N6c+exF0eu1qriUxNcZ/20JSldLzVXKWjDVuWOXHuL6jb6M9L+Lftxut6tT2sieUTSDPqnwuNbfmYax9s/0l+KzunNfaYX3GtJsknh70NO+LuETUX6gpdvskmtrsvBueL3MyfyOR+p9+C8S0hOMvx8KA5KxdcqSW9efnbr4HsIZ+XY7g6hTYnBb3V3CJ+LGaCtFff2AwAAAFphAAQAAAAgNhgAAQAAAIgN/gcIAAAAKENOW/9c1QP09BmWnh4fAAAAAHQYBkAAAAAAYoMlcAAAAEAZKtieuQSupw8wmAECAAAAEBsMgAAAAADERk+foQIAAADQBodvvi8JM0AAAAAAYoMBEAAAAIDYYAkcAAAAUIZ66heh9nTMAAEAAACIDQZAAAAAAGKDJXAAAABAGSpY7gJXCmaAAAAAAMQGAyAAAAAAscESOAAAAKAM8UWopWEGCAAAAEBsMAACAAAAEBssgQMAAADKUIElcCVhBggAAABAbDAAAgAAABAbLIEDAAAAyhB3gSsNM0AAAAAAYoMBUAsffPCBjDFavHhxd4cCAAAAoIPFagBkjPncx0knndTdIQIAAABbpGBtj3z0dLH6H6AVK1YEz+fPn68f/ehHWrZsWbCtsrJSa9eu7Y7QAAAAAHSBWM0ADR48OHjU1NTIGNNqm++9997TwQcfrKqqKu2+++567rnnitJ69tlnddBBB6myslLDhg3TrFmzVFdX19VFAgAAANAOsRoAtceFF16o8847T4sXL9bYsWN13HHHKZ/PS5Jee+01TZs2TV/5ylf06quvav78+frb3/6mM888c7Pp5XI5bdiwoejheOkBAAAA7eX00EdPxwBoM8477zxNnz5dY8eO1SWXXKIPP/xQ77zzjiTp6quv1vHHH6/vf//72mGHHbT//vvrV7/6le688041Nja2md6cOXNUU1NT9Pjs+ce6skgAAABAj5LP5/XDH/5Qo0aNUmVlpbbffnv95Cc/keN03lCKAdBm7LbbbsHzIUOGSJJWrVolSXrppZc0b9489erVK3hMmzZNjuPo/fffbzO92bNna/369UWPAftO6fyCAAAAAD3UVVddpRtvvFHXXXedlixZop/+9Ke6+uqrNXfu3E7LM1Y3QWiPdDodPDfGSFIwEnUcR6eeeqpmzZrV6rjhw4e3mV42m1U2my3alkilpKaOihgAAABxUtgKvgj1ueee05FHHqnp06dLkkaOHKl7771XL774YqflyQCoBF/4whf0xhtvaMyYMd0dCgAAAFC2DjjgAN1444166623NHbsWL3yyiv629/+pl/+8pedlicDoBJccMEF2nfffTVz5kx95zvfUXV1tZYsWaJFixZ16nQdAAAA0NPlcjnlcrmibW2thpLc36vXr1+vnXbaSclkUoVCQZdffrmOO+64TouP/wEqwW677aann35ab7/9tg488EDtscceuuiii4L/FQIAAAA6W8H2zEdbN/+aM2dOm2WYP3++7r77bt1zzz36xz/+oTvuuEPXXHON7rjjjk6rt9jOAJ100kk66aSTWm0fOXKkbItvsO3bt2+rbXvttZcWLlzYmSECAAAAZWf27Nk655xzira1NfsjSeeff75+8IMf6Nhjj5UkjR8/Xh9++KHmzJmjE088sVPii+0ACAAAAEDH29xyt7bU19crkShelJZMJjv1NtgMgAAAAIAyVA5fOvrvzJgxQ5dffrmGDx+ucePG6eWXX9bPf/5znXLKKZ2WJwMgAAAAAN1i7ty5uuiii3TGGWdo1apVGjp0qE499VT96Ec/6rQ8GQABAAAA6Ba9e/fWL3/5y0697XVLDIAAAACAMlSQ6e4QyhK3wQYAAAAQGwyAAAAAAMQGS+AAAACAMuTYf78PWmMGCAAAAEBsMAACAAAAEBssgQMAAADKEHeBKw0zQAAAAABigwEQAAAAgNhgCRwAAABQhlgCVxpmgAAAAADEBgMgAAAAALHBEjgAAACgDDmWJXClYAYIAAAAQGwwAAIAAAAQGyyBAwAAAMoQd4ErDTNAAAAAAGKDARAAAACA2GAJHAAAAFCGCsxllIRaAwAAABAbDIAAAAAAxAYDoG5kClJzTfHryk+tbEqySXebNZKxUjInNff2d4wm4u5rjWQcd9+iPKz7nhypkCneLttify+vphrJSXvHeT3Eptz9/TQSOXcfJ+Xma3eskzXecSnv2JaslGyUnIybjyl4mxPu/uk6Lx+5+7Usp+SW1Vip/zL34N4fW9mEm7ZM5KekQkWL7I2U2SAVKqVEU5ie9c8Cvz6MW9fGe12UvqREvnW5/PSN45Xdes9TUnaNVLEmLKtf9zJh+9pkmH7DEBtsl8I29MsuuXXl728ct0x+HH69RmPy96sfGja4ybvxBfFE+kK0/0lSqq5F/zLh+8H2SHv58Rvr9hG/bv3+k692fyZzYV6KpB3UiRRepWzYbkq4fbBoP8+IP62STUhNfaXmGisn7R2ecNOuWmnDWI37sAmpuTqsK1mpkDbBsW1eKY1UyIZlb3VOef2gbjsr+f0oUvboPtE6K2Tc7YnmyG6RdKPnbCIXPncyxXFaE/ZFqTi9aLrN1cVpOqmwPMZG0ky4OyWbwnaM9jUn6Z5zhax7HVAk3mifd4MrjlOSUvXF9WKjbRThnyuJvILzLL0pcoyfj/HqRF4fdVqnU6gI4/Pr3eTddJzI9TLo7961KmhvSfkqyXrltQkpu7Y4luCa4MdhI3F614Pqf4Z5+Plar1+2vD4VlSMSh+ReN6PXiaI238z1PtoH/XyNlRoHSM292qgDE6kHX8trqMLz0j9HgvY1LcrkFOcvue8n64vLkK6LhOJ/dhjvuWlRN165/M+baBmTjZv5fFJ4vI38c4CTVnidMGH5m2oidZIMr/eybpllvT4a6fPRtvPjlvdZmN7o7liocPuUFPbNfNZ7nZecrBdDSkXXhFbXCH9bPvI5JjfP9MawH0vu9T24jnoxFirDWJPRczMqcm5bE9nPu9Ym8mGZ/fMr+Nzyz59qqWJ1cTx++zR7v4s4La7x/u8nNrK/Kbg/C9kwraT3GeGk3fyj1xTTHPn8bxlXtD+2fN0DOdb0yEdPxwBoK9VyIAR0FstVBF2k5WAXAIBS8KsLAAAAgNjgLnAAAABAGeKLUEvDDBAAAACA2GAABAAAACA2WAIHAAAAlKECdyIqCbUGAAAAIDYYAAEAAACIDZbAAQAAAGXIYS6jJNQaAAAAgNhgAAQAAAAgNlgCBwAAAJQhvgi1NMwAAQAAAIgNBkAAAAAAYoMlcAAAAEAZ4otQS0OtAQAAAIgNBkAAAAAAYoMlcAAAAEAZcrgLXEmYAQIAAAAQGwyAAAAAAMQGS+AAAACAMlRgLqMk1BoAAACA2GAABAAAACA2WAIHAAAAlCG+CLU0ParWxo0bp+uvv767wwAAAACwlepRM0APP/yw+vbt291hAAAAANhK9agZoBEjRqimpmaL9jXGaMGCBZ0bEAAAANBDOUr0yEdP1+0Rrly5UmeddZbGjBmjiooKDRo0SAcccIBuvPFG1dfXd1kcDKgAAACArV+3LoF77733NGnSJPXt21dXXHGFxo8fr3w+r7feeku33Xabhg4dqiOOOKI7Q2y35uZmpdPp7g4DAAAAQBu6dQbojDPOUCqV0osvvqivf/3r2nnnnTV+/Hh99atf1UMPPaQZM2ZIkt5++20ddNBBqqio0C677KJFixa1Suu1117Tf/3Xf6myslK1tbX67ne/q02bNhXtc9ttt2ncuHHKZrMaMmSIzjzzTEnSyJEjJUlHH320jDHBa0m64YYbNHr0aGUyGe2444666667itI0xujGG2/UkUceqerqal122WUdWEMAAABA2wrW9MhHT9dtA6DVq1dr4cKFmjlzpqqrq9vcxxgjx3H0la98RclkUs8//7xuvPFGXXDBBUX71dfX69BDD1W/fv30wgsv6A9/+IMee+yxYIAjuQOZmTNn6rvf/a5ee+01PfDAAxozZowk6YUXXpAk3X777VqxYkXw+v7779dZZ52lc889V6+//rpOPfVUnXzyyXryySeL8v/xj3+sI488Uq+99ppOOeWUNsuSy+W0YcOGooeTz5dWeQAAAABK0m1L4N555x1Za7XjjjsG23K5nGpra4PXM2fO1CGHHKIlS5bogw8+0HbbbSdJuuKKK/TlL3852O+3v/2tGhoadOeddwaDqeuuu04zZszQVVddpUGDBumyyy7Tueeeq7POOis4bq+99pIkbbPNNpKkvn37avDgwcH711xzjU466SSdccYZkqRzzjlHzz//vK655hodfPDBwX7HH3/8Zgc+vjlz5uiSSy4p2rbNfl9S/2mHbkFtAQAAAOgI3X4TBGPCabJMJqPFixdr8eLFGjdunHK5nJYsWaLhw4cHgx9J2m+//YrSWLJkiXbfffeimaRJkybJcRwtW7ZMq1at0vLly3XIIYe0K7YlS5Zo0qRJRdsmTZqkJUuWFG2bOHHiv01r9uzZWr9+fdFjwD5T2hUPAAAA4Cso0SMfPV23zQCNGTNGxhgtXbo02GaMCZalVVZWSpKsta2OjQ6a/H1abovu66dVii3Ja3NL+KKy2ayy2WzRtkQqJafkyAAAAAC0V7cN0WprazV16lRdd911qqur2+x+u+yyiz766CMtX7482Pbcc8+12mfx4sVF6fzv//6vEomExo4dq969e2vkyJF6/PHHN5tPOp1WoVAo2rbzzjvrb3/7W9G2Z599VjvvvPMWlREAAABAz9Ktc1TXX3+98vm8Jk6cqPnz52vJkiVatmyZ7r77bi1dulTJZFJTpkzRjjvuqG9+85t65ZVX9Mwzz+jCCy8sSucb3/iGKioqdOKJJ+r111/Xk08+qe9973s64YQTNGjQIEnSxRdfrJ/97Gf61a9+pbffflv/+Mc/NHfu3CANf4C0cuVKrV27VpJ0/vnna968ebrxxhv19ttv6+c//7nuu+8+nXfeeV1XSQAAAEAbHJvokY+erlsjHD16tF5++WVNmTJFs2fP1u67766JEydq7ty5Ou+883TppZcqkUjo/vvvVy6X0957761vf/vbuvzyy4vSqaqq0l/+8hetWbNGe+21l772ta/pkEMO0XXXXRfsc+KJJ+qXv/ylrr/+eo0bN06HH3643n777eD9n/3sZ1q0aJGGDRumPfbYQ5J01FFH6dprr9XVV1+tcePG6aabbtLtt9+uyZMnd0n9AAAAAOhY3fpFqJI0ZMgQzZ07t2g2pqWxY8fqmWeeKdrW8n+Dxo8fryeeeOJz8zr11FN16qmntvnejBkzgu8dijr99NN1+umnbzbNtv5HCQAAAEDP1O0DIAAAAADtVw53XOuJqDUAAAAAscEACAAAAEBssAQOAAAAKEMF2/b3YOLzMQMEAAAAIDYYAAEAAACIDZbAAQAAAGXIYS6jJNQaAAAAgNhgAAQAAAAgNlgCBwAAAJShgmUuoxTUGgAAAIDYYAAEAAAAIDZYAgcAAACUIUd8EWopmAECAAAAEBsMgAAAAADEBkvgAAAAgDLEXeBKQ60BAAAAiA0GQAAAAABigyVwAAAAQBkqMJdREmoNAAAAQGwwAAIAAAAQGyyBAwAAAMqQY/ki1FIwAwQAAAAgNhgAAQAAAIgNlsABAAAAZYi7wJWGWutGTkZK1rvPrZGMIzVsY+Skw20+m5TkuPvISsZKMt7zgvvaJsJjoj+NdZ8394mk12K/VL2btjVSekO4XyJXHEOiEKZl8u62fKWUXlwtY6VUg/taklJ17k9jwzhs2iuDV36fsVKhQko2uK+batyyhZn7leamtXpcUpK0aYhpvY/3088nqrmXlGiWEnk3z+g+fpx+/fv1Y5NhHVojFbJunfvH+G1hrJRsLD7WOFL90LBO/DqWpObekcCc4vJG29MaN/1o2awpfp5sCGOM5t/yZ6rOhOlH//xhio9v+dymIrEoLH+Ymdt+beUfrTvrNpsya92fhQop0VScTtB+BS9dv58Yt938fq9EWMdR7x03UCYvZdZJVctN0M8SXnr1g0x4jA0fFZ8Vp7NphBevf575cUWeO2mvT1S0rm+/H2U/899wf6Qi57xfH9G0mvp4+/r15xTXfbReC5VhLMlc8TXDj9N/RPNqyU8/OCdMuM1vn8pP3MRtQmrq6/6M1n3S26/iM3e7sW5Zi9L2rlXRcz+IIXKetTz3TaRPZDa46ReyYf6btmvRD7w2TTS3zsd4574c9/2gXhPeMV7fzvVrkZ7CNg3q2krpjeF1XFZqrA1jjl77/OdFbVRwX+f6hjFn1rWo00j5i64FXn7R/pDdYIvziOQdPc5JRY6NxBoka6Tq5VLFqtZ14Jc/qpBtff3x2yO71k0vXx2m0/L60bJvJvJSvpf3nnedciL7RK9d+V5hXi37QHOf8DMz2L+yuLxF5U568eXDOks1eP25RdrJXNjPnWxxu/r146fn52MTkTwTkbi8drAJty/ZVNhfJDd9v9zRz2ef49WH357WhH3LP5f9c09WatymuL5y/Vq3SbIx0u8+50/l0f7nf6aZZjftZEO4Lb1RRdf34HePurD/NPcO69RYt6yJpkh9tvF7TfDcq9tg30RYLyYfntd+DIWK8FrXVlx+mVqeG9h6MAACSvB5v0wCHYn/bw2l67o7AgDA1oAlcAAAAEAZcixzGaWg1gAAAADEBgMgAAAAALHBEjgAAACgDBXEP4qWghkgAAAAALHBAAgAAABAbLAEDgAAAChD3AWuNNQaAAAAgNhgAAQAAACg2/zrX//S//f//X+qra1VVVWVJkyYoJdeeqnT8mMJHAAAAFCGtoa7wK1du1aTJk3SwQcfrEceeUQDBw7Uu+++q759+3ZangyAAAAAAHSLq666SsOGDdPtt98ebBs5cmSn5skSOAAAAAAdJpfLacOGDUWPXC7X5r4PPPCAJk6cqGOOOUYDBw7UHnvsoVtuuaVT42MABAAAAJQhxyZ65GPOnDmqqakpesyZM6fNMrz33nu64YYbtMMOO+gvf/mLTjvtNM2aNUt33nlnp9UbS+AAAAAAdJjZs2frnHPOKdqWzWbb3NdxHE2cOFFXXHGFJGmPPfbQG2+8oRtuuEHf/OY3OyU+BkAAAAAAOkw2m93sgKelIUOGaJdddinatvPOO+tPf/pTZ4QmiQEQAAAAUJYKW8EXoU6aNEnLli0r2vbWW29pxIgRnZZn+dcaAAAAgLJ09tln6/nnn9cVV1yhd955R/fcc49uvvlmzZw5s9PyZAAEAAAAoFvstddeuv/++3Xvvfdq11131aWXXqpf/vKX+sY3vtFpebIEDgAAAChDzlbwRaiSdPjhh+vwww/vsvyYAQIAAAAQGwyAAAAAAMQGS+AAAACAMrQ13AWuO1BrAAAAAGJjqxsAjRs3Ttdff313hwEAAACgB9rqlsA9/PDD6tu3b3eHAQAAAHQqx24dd4HralvdDNCIESNUU1PToWk+9dRTMsZo3bp1m91n3rx5DLwAAACAHm6rGACtXLlSZ511lsaMGaOKigoNGjRIBxxwgG688UbV19f/x+nvv//+WrFiRYcPrAAAAAB0rbJfAvfee+9p0qRJ6tu3r6644gqNHz9e+Xxeb731lm677TYNHTpURxxxxH+URyaT0eDBgzsoYgAAAOA/V9g65jK6XNnX2hlnnKFUKqUXX3xRX//617Xzzjtr/Pjx+upXv6qHHnpIM2bMkCRdfPHFGj58uLLZrIYOHapZs2YFadx9992aOHGievfurcGDB+v444/XqlWrgvfbWgI3b948DR8+XFVVVTr66KO1evXqLiszAAAAgNKU9QBo9erVWrhwoWbOnKnq6uo29zHG6I9//KN+8Ytf6KabbtLbb7+tBQsWaPz48cE+TU1NuvTSS/XKK69owYIFev/993XSSSdtNt//+7//0ymnnKIzzjhDixcv1sEHH6zLLruso4sHAAAAoIOV9RK4d955R9Za7bjjjsG2XC6n2tra4PXMmTM1aNAgDR48WFOmTFE6ndbw4cO19957B/uccsopwfPtt99ev/rVr7T33ntr06ZN6tWrV6t8r732Wk2bNk0/+MEPJEljx47Vs88+q0cffXSzseZyOeVyuaJtTj6vZHk3AQAAALoJd4ErTVnPAPmMCRs/k8lo8eLFWrx4scaNG6dcLqdjjjlGDQ0N2n777fWd73xH999/v/L5fHDMyy+/rCOPPFIjRoxQ7969NXnyZEnSRx991GZ+S5Ys0X777Ve0reXrlubMmaOampqix+pnHyuxxAAAAABKUdYDoDFjxsgYo6VLlwbbjDEaM2aMxowZo8rKSknSsGHDtGzZMv36179WZWWlzjjjDB100EFqbm5WXV2dvvSlL6lXr166++679cILL+j++++X5C6Na4u1tt2xzp49W+vXry961O4/pYRSAwAAAChVWa+/qq2t1dSpU3Xdddfpe9/73mb/D0iSKisrdcQRR+iII47QzJkztdNOO+m1116TtVafffaZrrzySg0bNkyS9OKLL35uvrvssouef/75om0tX7eUzWaVzWaLtiVSKSm/mQMAAACAz+GU91xGtynrAZAkXX/99Zo0aZImTpyoiy++WLvttpsSiYReeOEFLV26VHvuuafmzZunQqGgffbZR1VVVbrrrrtUWVmpESNGyHEcZTIZzZ07V6eddppef/11XXrppZ+b56xZs7T//vvrpz/9qY466igtXLjwc///BwAAAEDPUPbDxtGjR+vll1/WlClTNHv2bO2+++6aOHGi5s6dq/POO0+XXnqp+vbtq1tuuUWTJk3Sbrvtpscff1x//vOfVVtbq2222Ubz5s3TH/7wB+2yyy668sordc0113xunvvuu69+85vfaO7cuZowYYIWLlyoH/7wh11UYgAAAAClKvsZIEkaMmSI5s6dq7lz57b5/lFHHaWjjjpqs8cfd9xxOu6444q2Rf/PZ/Lkya3+7+eUU04punucJJ177rntjBwAAAAoTYG7wJWk7GeAAAAAAGBLMQACAAAAEBtbxRI4AAAAIG74ItTSMAMEAAAAIDYYAAEAAACIDZbAAQAAAGXIscxllIJaAwAAABAbDIAAAAAAxAZL4AAAAIAyVBB3gSsFM0AAAAAAYoMBEAAAAIDYYAkcAAAAUIb4ItTSMAMEAAAAIDYYAAEAAACIDZbAAQAAAGWIL0ItDbUGAAAAIDYYAAEAAACIDZbAAQAAAGXI4YtQS8IMEAAAAIDYYAAEAAAAIDZYAgcAAACUoQJfhFoSZoAAAAAAxAYDIAAAAACxwRI4AAAAoAzxRailodYAAAAAxAYDoO4WaYFCheSk3ef+z4CR0hu9p463zUrGSvmqcB/J3WZs66zSm1okacOHkwm356ukRM6LI+PtU3DzSza4rxN5KdkopRrcuBLNkjXuPomCu0+yOYzT5+9jjZRoahF3Xmru4z0vtI4/Wiab9F6bcHv0p7FSqq71sdk1bv3lqyMJ20hsXhyZte7rorrx9ks2hvEFxziSHKlQWRxzvsKNw0/DRuJNb4hscyLbN4b/0BhtH+O4+RorNfcuLnuhIoylUNG6LoL08u5ra7zj88VtEhxTKD42aKvI+9H02/oDlJ+Pn5YUPi9UeGVPSMlcuL/PmvAcSDSHdZyv8urBCeNtlbeR0nVuXk7a7avRvP1zLlo+/zzKV4avM+u8fZzi+vHjM07knMy3LnsyF7ZV9FxLNBfXR3CME5bHWElOi/Yzxa/9GIK688oW1EvkpzWRcyYimkbw2m9f//ik+7PyMxuUJ7Oh+DjJvb4kmqRcf/dntA2DeLxYWra5sZJNFZ8freK0UnO15KTCuJy0+zN6bYvWtR97kWj7R84Hv34KWff9pr621bUlvck7HyPp5ivDfFpeS4vaouW5aMNtTjaSXnXr/tGy7wVpRM5Da6S6wUaJSJ/KV0b2j5wzyaYWdd/is8PYsG6j8Qb1Gv2fa+NeE6P1FP2ZyLedRlHeLdq8UBFec2zCO8cT4bFNNW3XUSFTnId/rW7ZJ/xzolV7RH7ahBuX//na6v/MI8cGsUb6qVRcfzahomt2UZsmvH7t9QX/uhzE59eZ1y7GhueYXwfRNpTc88kvb3Ad895P1heXu36IDZ4Xld/fxymuq7b+5z56LfHLbVNSysurUNn688jP098/VRe2jeT9TpRp+/OlZd4tY/I/L4O4otdKuedAepOC61zLMrbq59jqsARuK8WJ27kS+fAXsbijr3Uu6jeUyP/7fYCOEP0jC9CTOXTUkjADBAAAACA2GAABAAAAiA0W8QAAAABlyBFL4ErBDBAAAACA2GAABAAAACA2WAIHAAAAlCHuAlcaZoAAAAAAxAYDIAAAAACxwRI4AAAAoAw5lrmMUlBrAAAAAGKDARAAAACA2GAJHAAAAFCGuAtcaZgBAgAAABAbDIAAAAAAxAZL4AAAAIAy5IglcKVgBggAAABAbDAAAgAAABAbLIEDAAAAyhB3gSsNM0AAAAAAYoMBEAAAAIDYYAkcAAAAUIZYAlcaZoAAAAAAxAYDIAAAAACxsdUNgMaNG6frr7++u8MAAAAAOpVjTY989HRb3f8APfzww+rbt293hwEAAACgB9rqZoBGjBihmpqaLdr34osv1oQJEzo3IAAAAAA9xlYxAFq5cqXOOussjRkzRhUVFRo0aJAOOOAA3Xjjjaqvr5ckGWO0YMGCDs/7gw8+kDFGixcv7vC0AQAAgM3p7qVuLIHrJu+9954mTZqkvn376oorrtD48eOVz+f11ltv6bbbbtPQoUN1xBFHdHeYAAAAAHqAsp8BOuOMM5RKpfTiiy/q61//unbeeWeNHz9eX/3qV/XQQw9pxowZGjlypCTp6KOPljEmeO276667NHLkSNXU1OjYY4/Vxo0bg/ceffRRHXDAAerbt69qa2t1+OGH69133w3eHzVqlCRpjz32kDFGkydP7uwiAwAAAChRWQ+AVq9erYULF2rmzJmqrq5ucx9jjF544QVJ0u23364VK1YEryXp3Xff1YIFC/Tggw/qwQcf1NNPP60rr7wyeL+urk7nnHOOXnjhBT3++ONKJBI6+uij5TiOJOnvf/+7JOmxxx7TihUrdN9993VWcQEAAICAI9MjHz1dWS+Be+edd2St1Y477hhsy+Vyqq2tDV7PnDlTV111lSSpb9++Gjx4cFEajuNo3rx56t27tyTphBNO0OOPP67LL79ckvTVr361aP9bb71VAwcO1Jtvvqldd91V22yzjSSptra2VdpRuVxOuVyuOO98XslEWTcBAAAAUFbKegbIZ0w40sxkMlq8eLEWL16scePGtRp0tDRy5Mhg8CNJQ4YM0apVq4LX7777ro4//nhtv/326tOnT7Dk7aOPPmpXjHPmzFFNTU3RY/Wzj7UrDQAAAAD/mbKefhgzZoyMMVq6dGmwzRijMWPGSJIqKyv/bRrpdLrotTEmWN4mSTNmzNCwYcN0yy23aOjQoXIcR7vuuquampraFevs2bN1zjnnFG3b+/Kb2pUGAAAA4CuHO671RGU9A1RbW6upU6fquuuuU11d3efum06nVSgU2pX+6tWrtWTJEv3whz/UIYccop133llr164t2ieTyUjSv007m82qT58+RY9EqqzHnwAAAEDZKesBkCRdf/31yufzmjhxoubPn68lS5Zo2bJluvvuu7V06VIlk0lJ7lK3xx9/XCtXrmw1iNmcfv36qba2VjfffLPeeecdPfHEE61mcQYOHKjKyko9+uij+uSTT7R+/foOLyMAAACAjlH2A6DRo0fr5Zdf1pQpUzR79mztvvvumjhxoubOnavzzjtPl156qSTpZz/7mRYtWqRhw4Zpjz322KK0E4mEfve73+mll17SrrvuqrPPPltXX3110T6pVEq/+tWvdNNNN2no0KE68sgjO7yMAAAAQEvd/YWn5fpFqMZaa7s7iLja5cJfyDiS30+cjGQcyRQkm5RM3t1urPs6WS85WUlWknGPM1YqZKWkd68Hf1u07wWvE5Kc4u0tWSM5aSnR7O/kxmQTbr7JnBtnoUJKr3fjMXl3PyflHudk3TIkc1K+IjzeWHcf460WDNL18pCVCpVSwssj0eLfrKLlcrJSsrF1Xfg/Jff4Qrb42PQmKV9dXMaW56lNSqk6t4zGhvv6+xnHfTipFvXoSDZdXMf5KrcejA23t2wfP02/HNarR5vwtisSr1feQtZ97fefaHmcjJtntC6CektLyaawP5i81wYt6rmllnVp8m5aRW3Sos1atkdQf5FjbFJKNUiFTOt6KeqHKm6LaHoyXr14CpVSxWdu+zgZNw85Xj4V3rkVWbHqx+i3Z8I/7wreOVlo+3zy29QmW6dprHcupKWmPlJmQ+Q97/xuea7654PfRnIkJYrL6feHaF0G6ea964NTHGNwfKJ1WaL5Bvz9vHPeT6PXcqu6IUb5KilVH6kjr94yG6Xmarf+U3Xeub6Za1GbP5PFsbdkbFjHNumeW4mmsD9GrwO+aBn8eivq35Hrh026be8fkxtgVfGpKYoz2eS2j9/ukvs6VR+eD4UK9xrWquyRczxoOz9/r+zRNrXGjcf5nJXS0Wur9a/VqTAt/3xpqx2i9dGqXhRe85x08TH+cWFikfK1wf8c8K9r0TQ219bRa5Px6jqafqHCvf5bU3y9axWn15ejd+QtZMPrVKt68K+5kX4RfAZupk/6+ciG524h45U1+pnbop5a1mG+0u1H0c9JP30nFfbNoDw2PG/9a4ofU1HciTbaxq9TL/2GgVaVq8KAWl6rW17DNyd6HfTPVyftxZpq+zPXv976x0Y/V4PrUhufSS37TpC3V+d+O/p9J6irSJn8a7R/7rQ8P6Nlf2PO2Z9f+G409ameGduiyb/o7hA+V9nPAAEAAADAluK/8AEAAIAyVA7LzXoiZoAAAAAAxAYDIAAAAACxwRI4AAAAoAyxBK40zAABAAAAiA0GQAAAAABigyVwAAAAQBmyLIErCTNAAAAAAGKDARAAAACA2GAJHAAAAFCGHLEErhTMAAEAAACIDQZAAAAAAGKDARAAAABQhhxreuSjVHPmzJExRt///vc7rpLawAAIAAAAQLd64YUXdPPNN2u33Xbr9LwYAAEAAADoNps2bdI3vvEN3XLLLerXr1+n58cACAAAAChD1poe+cjlctqwYUPRI5fLbbYcM2fO1PTp0zVlypQuqTcGQAAAAAA6zJw5c1RTU1P0mDNnTpv7/u53v9M//vGPzb7fGfgeIAAAAAAdZvbs2TrnnHOKtmWz2Vb7ffzxxzrrrLO0cOFCVVRUdFV4DIAAAACAcvSf3HGtM2Wz2TYHPC299NJLWrVqlfbcc89gW6FQ0F//+lddd911yuVySiaTHR4fAyAAAAAAXe6QQw7Ra6+9VrTt5JNP1k477aQLLrigUwY/EgMgAAAAAN2gd+/e2nXXXYu2VVdXq7a2ttX2jsQACAAAAChDtocugevpGAABAAAA6BGeeuqpTs+D22ADAAAAiA0GQN0o0SzZSAs4aSm9yd1uCpKx7nZr3P0Kld6Oxt3mv5doDn/6x0T5+5rmyEYvjZYPSUo2ue8HMfppO1KhojieRLPkZKWCd6MPY6Vko/s8H4lX3jGJvJuOG5j3tuM+TzSHxyZbfFeWsWF8kpRd474uZMN0gvImvPcq1YqTkuQUl7dlnfll8uuukCnez6a8dPy4vPxsUjJ5d5u/byLvtquTbqMcpjhN67120t4+NhKndeMIyhaJz88nqJu1YVrB8dG29bMvuDEHcUT6VMtHc+8wZmvC8kTT8tvOF5QzUmabDPuTn15Tn3B/vz6cbBhrtL/4/TFapkS0X3uxNAxyY7Ym7PeFFnfX9NMJ2iAppRrC7Zn1Xh2Z1scFz5PFP6P7OF6b9vq4OL+i+ojkn69yf2bXe++1qOOW/Vxy+0FRfbQ8FyJ9vKgsieK+F2Wi1yUTPl8/2sgaKVXnnp/Rfii57ehkpERTWNf++eDHEO0TLeP084nWb/TcDOrUq+tkzm0v0+z2lZZ93j8ng/Rb9EE/T1MozsN/3evDz1lWEmm3ys/ccrd8P9q2/rZoufw2a1lePz4pUr/Ra1W0zyaK6zWz0a3zaHrRGILrUuQ6EO2LUYVs5PgWnxFFZXEi10ATee61Z97rC8nGFmmoddmDWJ3wvLcJ97kT6aeJXKRvO+FzJ3I+WOP2D5nieFJ1xZ+tRbG0cY5F2zJal4l8mE+iyX0vs7H4+hZ8jntpm8hnT9Hnky3+jE01FMfnX/dkw/7pt72TVvAZ21bcfntEr20tr/WVK01RG0brUiruk0HyLfpV9OHn3dw7jNPki69HvnxleB1zUsVtY/Jem7T1mRl5bqz3GRi53gefb/5x/ueIx0l5nz1OuE+UbVFHPZljTY989HQMgLDFWv6S12O19SHW0Vl0wuLRtgavPTHNrsij5WCqI7QcAHWElh+qZaMz+lpX1EUnfKY6nbEQvAvOu3LRGZ8bXXFdK4Pf3yQV/1Er9jjv0A4MgAAAAADEBjdBAAAAAMqQZearJMwAAQAAAIgNBkAAAAAAYoMlcAAAAEAZcjrj7jAxwAwQAAAAgNhgAAQAAAAgNlgCBwAAAJQhWy5fWtXDMAMEAAAAIDYYAAEAAACIDZbAAQAAAGXIYQlcSZgBAgAAABAbDIAAAAAAxAZL4AAAAIAyZG13R1CemAECAAAAEBsMgAAAAADEBkvgAAAAgDLEF6GWhhkgAAAAALHBAAgAAABAbLAEDgAAAChDLIErDTNAAAAAAGKDARAAAACA2GAJHAAAAFCGHJbAlYQZIAAAAACxwQAIAAAAQGywBA4AAAAoQ9Z2dwTliRkgAAAAALHBAAgAAABAbLAEDgAAAChDfBFqaZgBAgAAABAbDIAAAAAAxAZL4AAAAIAyxBK40jADBAAAACA2GAABAAAAiA2WwAEAAABliO9BLQ0zQAAAAABigwEQAAAAgNhgCRwAAABQhrgLXGmYAQIAAAAQGwyAAAAAAMQGS+AAAACAcsRt4ErCDBAAAACA2GAABAAAACA2GAABAAAAiA3+BwgAAAAoQ9wGuzTMAAEAAACIDQZAAAAAAGKDJXAAAABAGbLcBrskzAABAAAAiA0GQAAAAABigyVwAAAAQBniLnClYQYIAAAAQGwwAAIAAAAQGyyBAwAAAMoRS+BKwgwQAAAAgNhgAAQAAAAgNlgCBwAAAJQhvgi1NMwAAQAAAIgNBkAAAAAAYoMlcAAAAEA5YglcSZgBAgAAABAbDIAAAAAAxAZL4AAAAIAyZPki1JIwA9SNnJRUqJCMlWSk7BrJOJKTlpyMZP3WMZKslK90t9mEu8146z7Tm7z0kt77kfeC4yUlmlsE0OKc8eNwUpIpuK9Nwd1mvRgy6919s2ulRJNUyLrxFrLe8Y7UsI23vxeHTbjHykjNvdzjZNwy+nHapJTIh3EE6bUM2XF/FrLuz2RjWI6W14BUvVcGG6bb3NvdP9nYuuxBfjaMUSaMy5fe4L2vSNnk1ZkTicV4MRS8elRkX+vWhTVyz0Ibxm/8/CLlCerGS79yVfjcWBWtAc718+rdhH3I3zfRFOYT1Je3r7+P1KJ+/DqIxGOcSB5J9z2bKq7rQOR5Mhf2K+PVc2aDihjHTTfRXLyv37fbSjeap5OSUnVuHRUqpKZ+7vbmXjYodzQd/3Wywe27vt7L82GbRMrVVtn886RoX68+64e0yM//s5NXd/57fp37MTTV2NbnsiJtasNj/LYI+mWyOJ6gL3jp+XUcLYO/b7rea1+/f3k/s2vcn7laq3xFmE+wX8F9XfFZ2Kb56uL+5rdlUBbT9nO/f/kxBfVuw/YyeffaI0mN/du+XiRyfoJhfShy3vjXPMk9HyWpUOn+rBsaXkv9n81+eSLbcjWRtBX226BM3nuFCq9dpFbnoJMMj/FjNta9tvvt1Wa9meL+0Fzlnqt+2fy0oud39DwP+kMkXv9RscZr0xbtZhMtrj2S0nWt698/tqmf+0ZTTZifoueRV0dBu3rlbe7lbi/4fS0V7pPrG6mLSDzpjcX9JdcvEqfXZvle4Ta/bYM4/Drwzx/jXktaXU+te53xj/H7eb7Kfd3cR8HnoV/nxobtL3mfpZHzu6mvdctSKP69IGgzr00S3meJkw7rI1+t4DPWl6ovLlcuUv+ZjZF2ip7zkXPORn87bNHeLa91fhz+54vx+mAy5z6ksF8G11/vepSqD/dxMiriZMOyR9vQPzaI1YTXguz6sH6in+n+51PQx6x3nYr8ntLyeo+tGwOgrRR/EEBXCQZ3QGfjuoauwi/BwFaNJXAAAABAOWKwXhJmgAAAAADEBgMgAAAAALHBEjgAAACgDHEXuNIwAwQAAAAgNhgAAQAAAIgNlsABAAAA5Yi7wJWEGSAAAAAAscEACAAAAEBssAQOAAAAKEvcBa4UzAABAAAAiA0GQAAAAABigyVwAAAAQDniLnAlYQYIAAAAQGwwAAIAAAAQGyyBAwAAAMoRS+BKwgwQAAAAgNhgAAQAAAAgNlgCBwAAAJQjyxehloIZIAAAAACxwQAIAAAAQGywBA4AAAAoQ5a7wJWEGSAAAAAAscEACAAAAEBssAQOAAAAKEcsgSsJM0AAAAAAYoMBEAAAAIBuMWfOHO21117q3bu3Bg4cqKOOOkrLli3r1DwZAAEAAADlyJqe+WiHp59+WjNnztTzzz+vRYsWKZ/P60tf+pLq6uo6qdL4HyAAAAAA3eTRRx8ten377bdr4MCBeumll3TQQQd1Sp7MAAEAAADoEdavXy9J6t+/f6flwQwQAAAAUIZMD70LXC6XUy6XK9qWzWaVzWY/9zhrrc455xwdcMAB2nXXXTstPmaAAAAAAHSYOXPmqKampugxZ86cf3vcmWeeqVdffVX33ntvp8bHDBAAAACADjN79mydc845Rdv+3ezP9773PT3wwAP661//qu22264zw2MABAAAAJSlHroEbkuWu/mstfre976n+++/X0899ZRGjRrVydExAAIAAADQTWbOnKl77rlH//M//6PevXtr5cqVkqSamhpVVlZ2Sp78DxAAAACAbnHDDTdo/fr1mjx5soYMGRI85s+f32l5MgMEAAAAlKN2fuloT2Rt16/jYwYIAAAAQGwwAAIAAAAQGyyBAwAAAMpRD70LXE/XITNA69at64hkAAAAAKBTtXsAdNVVVxXdleHrX/+6amtrte222+qVV17p0OAAAAAAoCO1ewB00003adiwYZKkRYsWadGiRXrkkUf05S9/Weeff36HBwgAAACgDbaHPnq4dv8P0IoVK4IB0IMPPqivf/3r+tKXvqSRI0dqn3326fAAAQAAAKCjtHsGqF+/fvr4448lSY8++qimTJkiyb2Hd6FQ6NjoAAAAAKADtXsG6Ctf+YqOP/547bDDDlq9erW+/OUvS5IWL16sMWPGdHiAAAAAANpQBsvNeqJ2D4B+8YtfaOTIkfr444/105/+VL169ZLkLo0744wzOjxAAAAAAOgo7R4ApdNpnXfeea22f//73++IeAAAAACg05T0RahvvfWWnnrqKa1atUqO4xS996Mf/ahDAgMAAADwOazp7gjKUrsHQLfccotOP/10DRgwQIMHD5YxYcUbYxgAAQAAAOix2j0Auuyyy3T55Zfrggsu6Ix4AAAAAKDTtHsAtHbtWh1zzDGdEQsAAACALWS4C1xJ2v09QMccc4wWLlzYGbEAAAAAQKdq9wzQmDFjdNFFF+n555/X+PHjlU6ni96fNWtWhwUHAAAAAB2p3QOgm2++Wb169dLTTz+tp59+uug9YwwDIAAAAKArsASuJO0eAL3//vudEQcAAAAAdLp2/w+Qr6mpScuWLVM+n+/IeAAAAACg07R7AFRfX69vfetbqqqq0rhx4/TRRx9Jcv/358orr+zwAAEAAACgo7R7ADR79my98soreuqpp1RRURFsnzJliubPn9+hwQEAAABAR2r3/wAtWLBA8+fP17777itjTLB9l1120bvvvtuhwQEAAABAR2r3AOjTTz/VwIEDW22vq6srGhABAAAA6Dx8EWpp2r0Ebq+99tJDDz0UvPYHPbfccov222+/josMAAAAADpYuwdAc+bM0YUXXqjTTz9d+Xxe1157raZOnap58+bp8ssv74wYt1qFChXdvz3VICWaJVNwf8pKMu7PVL2UapSM475vCpIcL52sl4Dx3vceCf8GfVZSwstP7nuyXhqmOBbjpZlskmxCclLu9mSTZJNSwyD3/Yo1VsmclNkgJXJSxRp3/7oRVhWr3b9IpDdI1o/Jy884Cnudl7c1kslL6U1WiZy7LbvG3e7zn9uEe5yTdn/maqVEUyQ9E5bBFNyY/Tq2CSmZ8+rRuo+W7xvr1kUyF9aVH4s13nFOJE+F+ykhNff2Xls33XyllF0ftqWfh01I6U3hX27y1WHcfd9xwjR9jhtTsinc7qclSU7Ge27cNgtijdyk0VgpUQjjTTR75TBhW/g/GweGx5iCVD/EKeqrhaxbJr+cQb6J4nLKeHXs8ftkc43Xpibsl5JXz97+jvczXxW2f3Rfvx4S+bAejJV6f+SmYROSTbn1ZhwpvcFNpGGwE/ZJG6ZV874jGS89R6pYUafmPmFdu0+K+6Kfjn+etozNWKmpr1P0F7pUfaQN8mGf8uve728Vn5qicimh8Lz1Yilkw/5kk255/XqM1mnQvpH4/RhztTbIwz/nbSJS514e2XVWxkrJRuNepxwp2RDWjU26r+uHSM1V7ram/k5YNq89rPHibBFHERMpg39+enWc7xU5zjtfs+sibdQiHV+i2StPhXusNVKqrviaJ0n5KjdDm7ZFdemfU35awfO8lKwP96nYf3VQn8E5aLxzzQnbMtr//NgkqWGQW8/WFOcdXIO8+mx1/TLSptEF5SvD8yiart/2iXz43BTC402kbxkr1Q0Jn/vndDQtKex3TjLSz7z+bFPuz+p/uoVIb4z03RbtGz0frZEyG922kXV/WqPgs8Hti2HdpTeGsTX1Ka6z9Ea3Dorarqm4Pv14gtj8Td61rZDxXjthuSX3mutfAxPedTnpfbb49e6XR3L7gWkOy2oTxfVvt3ELmK+UmqvDY4JjC1Iib93do3k4UqHChp+nXl3k+oV9xNjI55C89CP11Njfey9yLiZzCj9Tbbi/32ZBH4pcv3L9vLrJeufCZ97nsHedj7aDvPp0MlL9tm78/rXRrzv/cyb4TCtEjlVxGyYb3GNyNe7PZM5tD/93Av/3JD//ZKNX170jaZvi/N0nLcqOrUa7B0D777+//vd//1f19fUaPXq0Fi5cqEGDBum5557Tnnvu2RkxohScsOgq9DV0ESfd3REAQA8THdH3pEcP1+7/AXr11Ve122676Y477mj13oIFC3TUUUd1RFwAAAAA0OHaPQM0bdo0vffee622/+lPf9I3vvGNDgkKAAAAADpDuwdAp59+ug455BCtWLEi2DZ//nx985vf1Lx58zoyNgAAAACbY3voo4dr9xK4H/3oR1q9erWmTJmiZ555Ro8++qi+/e1v66677tJXv/rVzogRAAAAADpEuwdAknTttdfqhBNO0L777qt//etfuvfee3XkkUd2dGwAAAAA0KG2aAD0wAMPtNp21FFH6emnn9Zxxx0nY0ywzxFHHNGxEQIAAABorQyWm/VEWzQA+rw7u91222267bbbJEnGGBUKhc3uCwAAAADdaYsGQI7T1jfVAQAAAEB5Kel/gAAAAAB0L8MSuJK0+zbYkvT0009rxowZGjNmjHbYYQcdccQReuaZZzo6NgAAAADoUO0eAN19992aMmWKqqqqNGvWLJ155pmqrKzUIYcconvuuaczYgQAAACADtHuJXCXX365fvrTn+rss88Otp111ln6+c9/rksvvVTHH398hwYIAAAAoA0sgStJu2eA3nvvPc2YMaPV9iOOOELvv/9+hwQFAAAAAJ2h3QOgYcOG6fHHH2+1/fHHH9ewYcM6JCgAAAAA6AxbvATulFNO0bXXXqtzzz1Xs2bN0uLFi7X//vvLGKO//e1vmjdvnq699trOjBUAAACAjyVwJdniAdAdd9yhK6+8UqeffroGDx6sn/3sZ/r9738vSdp55501f/58HXnkkZ0WKAAAAAD8p7Z4AGRtOMQ8+uijdfTRR3dKQAAAAADQWdp1FzhjTGfFAQAAAKAd+CLU0rRrADR27Nh/Owhas2bNfxQQAAAAAHSWdg2ALrnkEtXU1HRWLAAAAADQqdo1ADr22GM1cODAzooFAAAAwJay/HtKKbb4e4D4/x8AAAAA5W6LB0DRu8ABAAAAQDna4iVwjuN0ZhwAAAAA2oP5iZJs8QwQAAAAAJQ7BkAAAAAAYqNdd4EDAAAA0DPwRailYQYIAAAAQGwwAAIAAAAQGyyBAwAAAMoRS+BKwgwQAAAAgNhgAAQAAAAgNlgCBwAAAJQh7gJXGmaAAAAAAMQGAyAAAAAAscESOAAAAKAcsQSuJMwAAQAAAIgNBkAAAAAAYoMlcAAAAEA5YglcSZgBAgAAABAbDIAAAAAAxAZL4AAAAIAyxBehloYZIAAAAACxwQAIAAAAQGwwAAIAAAAQGwyAAAAAAMQGAyAAAAAAscFd4AAAAIByxF3gSsIMEAAAAIDYYAAEAAAAIDZYAgcAAACUIb4ItTTMAAEAAACIDQZAAAAAAGKDJXAAAABAOWIJXEmYAQIAAAAQGwyAAAAAAMQGS+AAAACAcsQSuJIwAwQAAAAgNhgAAQAAAIgNlsABAAAAZYgvQi0NM0AAAAAAYoMBEAAAAIDYYADUjWxKMgX/hZTrJzX1kvLVUnaNu9k47vRmMieZZnc/GckmJJt092nqE06BWv89731/uylI2XXePglvuwnzN9bdLkmFCjcW40jNXtqFCinRHO7b2N+ocRupsVZyMlJ2nZWsVLnCKNXgptXc20vXhPkmmiQn7ZYj2ei+Z6xk09K6sUb5ane/QrZFZZlIWRw3FuO4aTT3DuvQFMLyNVdLctx6sMbdv6lGaq5yyye578t47xfcn5WfenXn1U0h66bn55/rLzkt4rMJyUlJFZ+G9Si57ZbrK6Xq3fyVCGNJNnh14z9PuseuHh8mEOSbkJJNUv0gr34ybhp+3SbykbopRPpCMqwba6S6bW3Q1k193XY1joK7yPj9Lb0xTENGqlqecOOwYUw2EWnbpNdnbeTht4kTlsXx2iLRFPa19KYWTe2EZZZ1zxPJ/ZnMhe3gZNyfjQMi7WCkxn5u+vVDpJq3rRI5twz5Kq99VyaCPuHHLyOtH51QxaduO9qE9NGXa5Te4JXXj8mEZVHknOn1T1vUR2xCahhsZY2UWZcI85HU3CvcR054zvp1VTfCcftksrgv+X07aFMjNfX3M3T7pG1xnvixGifSB/268s6T7GdhcMaR8pWSyXvHFdw6l6TMJrc8sl4fM26efrnzVd45Y8NrRdU/E+6567hl9c8pJ6mgj/hlzGwovo4F145InSfyUmatl3fKvVYmG6VNI52gj0c5ab+wYXnTm8LnyeYwr4rP3F0rPnUTKVQ5brtH68xLv3GbsP/YhJuPH3vjs7XBvtZISnjnakLhtSZfXPZEcxhjdp0J8ilUhmV3nyhoA2vCevb3qViRVKIpbLvmPmEe/vnipMJ0g8+KFp8p1rjXm3xV2Df9cz+4VtiwXTPR88QJr582EV4KCpWR/BJhmfx29h/GkeqGSs013nWy2etf1eG+Jh+59vmfYY6UWRfZx4vVv377+1esKe4jfv+MxuTXSbSP2Bb/MBD97E7mws83yT3X/LoO0kyF53S07/h1nn2nIrjOFyq8g7z3CxXuvo39jRoHus/TdWFdVy03YRs5Kj6PvDgbBoTb/M9gv/6z67129vuqkZL1YXqFbLh/0GaJMD2/DFWfFC/HytW4nzNtHedfNxJNUmaNG7+TinymeOn6n/V+fUhu2f00/Db02yfh9buGQd41yYu/YnUkXa8NnEyYtl8n0brz27fH32XN9tBHD8cAaCsV/dAGgK1B8McOAAD+AwyAAAAAAMQGd4EDAAAAyhB3gSsNM0AAAAAAYoMBEAAAAIDYYAAEAAAAlKPuvttbB94F7vrrr9eoUaNUUVGhPffcU88880xpCW0BBkAAAAAAus38+fP1/e9/XxdeeKFefvllHXjggfryl7+sjz76qFPyYwAEAAAAoNv8/Oc/17e+9S19+9vf1s4776xf/vKXGjZsmG644YZOyY+7wAEAAADlqIfeBS6XyymXyxVty2azymZbftO91NTUpJdeekk/+MEPirZ/6Utf0rPPPtsp8TEDBAAAAKDDzJkzRzU1NUWPOXPmtLnvZ599pkKhoEGDBhVtHzRokFauXNkp8TEDBAAAAKDDzJ49W+ecc07RtrZmf6KMMUWvrbWttnUUBkAAAABAGeqpX4S6ueVubRkwYICSyWSr2Z5Vq1a1mhXqKCyBAwAAANAtMpmM9txzTy1atKho+6JFi7T//vt3Sp7MAAEAAADoNuecc45OOOEETZw4Ufvtt59uvvlmffTRRzrttNM6JT8GQAAAAEA56qFL4Nrrv//7v7V69Wr95Cc/0YoVK7Trrrvq4Ycf1ogRIzolPwZAAAAAALrVGWecoTPOOKNL8uJ/gAAAAADEBjNAAAAAQDnaSpbAdTVmgAAAAADEBgMgAAAAALHBEjgAAACgDPXUL0Lt6ZgBAgAAABAbDIAAAAAAxAZL4AAAAIByxBK4kjADBAAAACA2GAABAAAAiA2WwAEAAABliLvAlYYZIAAAAACxwQAIAAAAQGywBA4AAAAoRyyBKwkzQAAAAABigwEQAAAAgNhgCRwAAABQjlgCVxJmgAAAAADEBgMgAAAAALHBEjgAAACgDJnuDqBMMQMEAAAAIDYYAAEAAACIDZbAAQAAAOWIu8CVhBkgAAAAALHBAAgAAABAbLAEDgAAAChDhiVwJWEGCAAAAEBsMAACAAAAEBssgQMAAADKEUvgSsIMEAAAAIDYYAAEAAAAIDZYAgcAAACUI5bAlYQZIAAAAACxwQAIAAAAQGywBA4AAAAoQ3wRammYAQIAAAAQGwyAAAAAAMQGS+AAAACAcsQSuJIwAwQAAAAgNhgAAQAAAIgNlsABAAAAZYi7wJWGGSAAAAAAscEACAAAAEBssAQOAAAAKEcsgSsJM0AAAAAAYoMBEAAAAIDYYAkcAAAAUIa4C1xpmAHqRpl1Una9ZBNuBzaO1LiNVTIn1Q11t1nj7tvcW0o0S9YfsiYkGffhd/5CZfieNZKTctOWkWSlXH/vfRPGYL0ekKwPt2fWS6k6N41Ug7ejE75vvfRN3k03vVFat4ORsVKiSWrq7W53IrFa45Yvu07K9fcCtu57/n6FKkeJZne7TXnl8upGNoxVkuqHWFnjppfIb76O/WNl3BiSjW7aTsYG9e7XkU16Rc1IjQPc19a4r/33rJGae0UysF4exo2jcZtwPymMrZD1tjlhuyabFLRhZkOYXqHCBmlY48ZXyEi5vlJ6k7tbPhKDjbZLQsqujVwQ/TJ6dZzIGXf/hNufUvVh2wT5GbdNo+lXrPH282LPrG+Rv+PWk7Hhw2+vfFVY/046jFVyz4Fcjd9YYfp+mpLbF411+1syF7ZrstF9nt4Y1pOMVDeuSYkmt+7rBxllNnhl+MzdP7tWrdiEVDe8oMymMMbBB/9TqYbidvDz9usi2ew+b+ptitpMRkpvcLdV/6v4A8pJh/3SySo4r4LnBeP2Wae4Xf1+7K/3tgkps9aEsdS7fcoa71qR9GJNuvvmq8IyRH86mbAdrZHy1WFMMu45bY306QT3oMwG9xywxm0b/1hTKC6P/PPNhPVWyLrPE83hPv7++epwX7+/RMtvjZTeEF7nEs1unyhUSlX/SoR17OfnhHXu10NQdq/8jf0ifdUWx1b9YbLVtaFqlYJz3c8r1889H/123/aJukjGYTmifTfYHrl22KT72u/XfizB9daG5fKf+3n6ZUhvjLznneNBufJhWYJrqQnj8WPxz99EU3httknvGpFwfxYqI3E5Ut12xeegIm2R7+Wml9oUec97GCes22id5ausqlZ49ds3LJtfXicb7u5fx4PrvN9mRkoUvM/BaD+rCJ8HaZjIT69M8vpEU58W+3t5+O3ppKWCl6Z/XiSavPpJhekWMgp/4zLee5F+N/R/czJ5qeJTqeIzE5RNkpq9GBoGWvfanPDyirRPELd3XGad+zyR8z5vcgrOt+Aa5HGSbppBOjbcx6/7onMy2boO/Ta1Cbf8/mdPMuf1p+bI+R1pu0Kl1Ouf1t0nH6ZrrFS1Umqu8a4zkfOwuZd7vQn6sfWub0ZqrnZfZ9eGbRWtF39/J+Nem1P1YZmLzitfpO9g68IAaCvFXwQ6l8PcKboK53KIX0Q6F/Ub4rzrVC0HQ0BX49c4AAAAoBwxWC8JM0AAAAAAYoMBEAAAAIDYYAkcAAAAUI5YAlcSZoAAAAAAxAYDIAAAAACxwRI4AAAAoAzxtSelYQYIAAAAQGwwAAIAAAAQGyyBAwAAAMoRS+BKwgwQAAAAgNhgAAQAAAAgNlgCBwAAAJQhY1kDVwpmgAAAAADEBgMgAAAAALHBEjgAAACgHLECriTMAAEAAACIDQZAAAAAAGKDJXAAAABAGTIsgSsJM0AAAAAAYoMBEAAAAIDYYAkcAAAAUI5YAlcSZoAAAAAAxAYDIAAAAACxwRI4AAAAoAxxF7jSMAMEAAAAIDYYAAEAAACIDZbAAQAAAOWIJXAlYQYIAAAAQGwwAAIAAAAQGyyBAwAAAMoQd4ErDTNAAAAAAGKDARAAAACA2GAJHAAAAFCOWAJXEmaAAAAAAMQGAyAAAAAAscESOAAAAKAMcRe40jADBAAAACA2GAABAAAAiA2WwAEAAADlyLIGrhTMAAEAAACIDQZAAAAAAGKDJXAAAABAGeIucKVhBggAAABAbDAAAgAAABAbLIEDAAAAyhFL4ErCDBAAAACAHu2DDz7Qt771LY0aNUqVlZUaPXq0fvzjH6upqandaTEDBAAAAKBHW7p0qRzH0U033aQxY8bo9ddf13e+8x3V1dXpmmuuaVdaDIAAAACAMmSc7o6g6xx66KE69NBDg9fbb7+9li1bphtuuIEBEAAAAIDuk8vllMvlirZls1lls9kOzWf9+vXq379/u4/jf4AAAAAAdJg5c+aopqam6DFnzpwOzePdd9/V3Llzddppp7X7WAZAAAAAQDmyPfMxe/ZsrV+/vugxe/bsNotw8cUXyxjzuY8XX3yx6Jjly5fr0EMP1THHHKNvf/vb7a42lsABAAAA6DDtWe525pln6thjj/3cfUaOHBk8X758uQ4++GDtt99+uvnmm0uKjwEQAAAAgG4xYMAADRgwYIv2/de//qWDDz5Ye+65p26//XYlEqUtZmMABAAAAJQhE6MvQl2+fLkmT56s4cOH65prrtGnn34avDd48OB2pcUACAAAAECPtnDhQr3zzjt65513tN122xW9Z237RoLcBAEAAABAj3bSSSfJWtvmo72YAQIAAADKUQm//IMZIAAAAAAxwgAIAAAAQGywBA4AAAAoQ3G6C1xHYgYIAAAAQGwwAOpGhazkpCR5o/dUvZSuM0rVSYlmSY673SakhsFWzTWSKUjWSCYvGcc9tpCVbNJL1LjHWeO99PaRkRoH+gmG6Srh/vWgYo23zUu7ubd7TLLe3Zbv5R5nk+72+m2tbEpq7m2V6y+NvvpNWSMlHCmZc/NN5txjTMH7C4WVmqulZIORsVKhwo3VFNy8k40miDVf5cVS8NKwbprGutuT29XLWGnTCOvu5x0nE+6Tr1bxe5Ka+1glclLVcuPWTbSO5O5bP1jKV9kgLuO4deKnlaoLy2QKXhsatx3SG1SUbjInNQxvDtKyKbfejZUaBnplc6Rmr36VkFKb3NhMwSuPE/YPvw4qP/H6h1euzLowz0STl0ehuC9IUnatm4ccd99CNvzrkfHyl8L29+tz7S6OjOP1GSNVrLVu+f1jC14/TLh9xM/fWCnh9VXjSMlGd5uTdo/L9ZcyG8P2tZErUr467G824aaTaPbyiPTvVL3Cfm2lVEWzmvq5ZTUFaeNIKxkpu87dv7FWxbx+NvD5hAppL14rffrIdm79OGH/DfL28t+wc14y0sZRNtxuFJyXxpESeRv0a2Ol9KZIv4z85c565Rz151xRXMH7iTANPw8nE5bdOFJTn7ANg3MnH/60Ka9dnHC/ZKOK+pnf76z3aO4dqV+58TeMaXL7be+wzdKbIu8PsUX91ybc4xN5r217eflHzmuTj/Q5f5tfRzbcXvOeW5+5Wqmpr5VNSo0D3OD8/Y3XVtl1xU0dnAteWRsH+hfDsC4zG23YR/24m900myvd+qn4NNoGVhWrwzpauW912D/9897vN1at3pOkjds7wfOk3/x+3fjtkfTqMumlkfDiilxvtnktp6aa8PMgXxXWo02EddzUzwZ92CbDOvM/XySpapUNP1ci9S8jVa0M+4NNSflqNz2TD/N2UuH5aSPt6gbb+jrhfxZJUu8PjRoHuMdVL3fLma8K661qZdjeDdt4fTWtIAY/n00jHaUawryNdftsNI7gHDRhHfj90ialqk+8fZxIGSLnbaLZvVaZgtuvjeOeA8YJY5bx2ioftlXjICdoW0lauXdWNimlGq0aB9jgdwNTkCo+c4/JbDDB7wZB3TkKruf+eSsrJbx6be7j9YVqBeeSiXwuWCNVr3SCMlqvbbLrw/O2qW/Yd6J9Mqgzr24bBob1Iu9a63j91e8Pxons4/XLfKWRTUiNA8K+6KSl9Ear7Gq3LEEbqPVnhfs7g9soycawXI7ftx3JafHbbrJRqh8k5foV99Po56USbcSMrQZL4LZSxhZdo9HBUo3uL7gIf2kBOlvlKjobukbRL8LocK0GMSgdl8WS0P0AAAAAxAYDIAAAAACxwRI4AAAAoAyxDL00zAABAAAAiA0GQAAAAABigyVwAAAAQDmyrIErBTNAAAAAAGKDARAAAACA2GAJHAAAAFCGuAtcaZgBAgAAABAbDIAAAAAAxAZL4AAAAIByxBK4kjADBAAAACA2GAABAAAAiA2WwAEAAABliLvAlYYZIAAAAACxwQAIAAAAQGywBA4AAAAoRw5r4ErBDBAAAACA2GAABAAAACA2WAIHAAAAlCNWwJWEGSAAAAAAscEACAAAAEBssAQOAAAAKEN8EWppmAECAAAAEBsMgAAAAADEBkvgAAAAgHJkWQNXCmaAAAAAAMQGAyAAAAAAscESOAAAAKAMcRe40jADBAAAACA2GAABAAAAiA2WwAEAAADliCVwJWEGCAAAAEBsMAACAAAAEBssgQMAAADKkOGLUEvCDBAAAACA2GAABAAAACA2WAIHAAAAlCOnuwMoT8wAAQAAAIgNBkAAAAAAYoMlcAAAAEAZ4i5wpWEGCAAAAEBsMAACAAAAEBssgQMAAADKESvgSsIMEAAAAIDYYAAEAAAAIDZYAgcAAACUI+4CVxJmgAAAAADEBgMgAAAAALHBEjgAAACgDBlWwJWEGSAAAAAAscEACAAAAEBssAQOAAAAKEfcBa4kzAABAAAAiA0GQAAAAABigyVwAAAAQBkyTndHUJ6YAQIAAAAQGwyAAAAAAMQGS+AAAACAcsRd4ErCDBAAAACA2GAABAAAACA2jLXMnXWX8ef9Qk5SUkKyRsr1t8qsN0o2SjJSoUJKNEs2IaU3Ss29vAO9/RNN7vNEs+SkJJuS5LjHykimWbJJ73leMtZNy6YkWfdhvNa3xr2TiPWGxBWrpVxfqVAlJXLufoWM+zORk5prpMxaNy2Tl3L9pfQmL14j2bS73SaLy5xqkApZd59kk5um5KXbJOWr3TSSje5+kpdHwYvRizfR7B7rpN3nxiu3Ne6+Srg/nbSXvle2RJOUbJYKafc9m5SSOS9Ox43bmjBOGSlfIaUaw7o1BS+vRKQOvWOdpJTIh9sLWSmz3q2fVL23n1cniXyYr+Q+N9aLO+Ol4YTx5Pq5/cDJeGXJe5Xq75d09w14z23CLaOTkuq3K6j6o2RwvJ+XTXrpeGVLNkr5Sq/PJKWqFVb1Q4wSTV6cBTc9Ga8vKWwbv56ctFfGRFj/Tsrd5tevkwrbx8/fpqR8lZRZ56aRbArbSvJidKRCpZuWk5aSDWGx67d1lF2TkJNy05C8fmAix5uwrozj9cmU20b+OSDr1k0i7+YX9LGk27dlwvIkc24/CdJOuudDc++wnwR1UQjrJ1UXtmdmvXuON/dy40g0S042cq6rdb3m+lll15qgP1qv7Ww6bAe/LPLOccc7n/zrgSlEzlPr9ZVMpBt5bZ2vktJ17r6FjNsu0f4nuXEa68ZRqPCuAWl3u5NScF6mGtz+FfSNpNuG/jnn9xc/3aCtrHseZNa5dZOKxOOfD/45459/0bozjtdWVV6bFrx+1OzVQyI8L1MNUnN1pIx+enn3Z7LRPS5f7ZXbi7m5l9cnvOu4KYR90DhhPn7d+ueTvy3o86ni88dJhfXh//Svf/51JL3J3c+/fth0pB2bw+tbZqNb/9G69evIP6frhzqqeSuh5uqwjWTdNkw0ef0t0aIf+eezd3747WATbt/x85SNXHNs8TbjuPWezLlpNvdx29nvl9b7zPNjt369RM/PgpteocJtR18QTzLyWaHwp7wy+XVgHKmpj1uv0X5VVG8JKb0hjLO5d3hsoils9yBdr54d77NHct+rWC011roxJxuLrzeZdVJTX6/sOa8dvTo3Be/zMHruROt9k9RUU1xv6Tq3n/qf0U7GTTcot42UL/Iz6Kd+u9nI53PCPYedbNhnkzn33AyuqV7f9Y+R413Dvf6a3uTWt59fstEtdzLn9l95eQefbZHrgpN288qucWMoVLj1lq92y1mo8D4nvOukTbp1ll0X+V0iH9aff63yY3/z8rPVU03d/7LuDqFNi579YXeH8LmYAdpadcKw1r94dqTOuH2j7YL/bCv6paGjdEKaXXJ7zE64ikR/aekoTvrf79NemfUdn2ZLwS9nHZpoJ6TZBX9Ka+7d8Wl2xnUtVd/xaQZ/8OhMndAvOuNc7oq+1il5dEL9tvwjY8ck2glpttQJn02dcd5h68UACAAAAEBscBc4AAAAoAwZ/pOlJMwAAQAAAIgNBkAAAAAAYoMlcAAAAEA5YglcSZgBAgAAABAbDIAAAAAAxAZL4AAAAIBy1BXf97cVYgYIAAAAQGwwAAIAAAAQGyyBAwAAAMoQX4RaGmaAAAAAAMQGAyAAAAAAscESOAAAAKAcsQSuJMwAAQAAAIgNBkAAAAAAYoMlcAAAAEA5YglcSZgBAgAAABAbDIAAAAAAxAZL4AAAAIBy5HR3AOWJGSAAAAAAscEACAAAAEBssAQOAAAAKEOGu8CVhBkgAAAAAGUjl8tpwoQJMsZo8eLF7T6eARAAAACAsvH//t//09ChQ0s+ngEQAAAAUI6s7ZmPTvTII49o4cKFuuaaa0pOg/8BAgAAANDjffLJJ/rOd76jBQsWqKqqquR0GAABAAAA6DC5XE65XK5oWzabVTabLTlNa61OOukknXbaaZo4caI++OCDktNiCRwAAABQjrp7qdtmHnPmzFFNTU3RY86cOW0W4eKLL5Yx5nMfL774oubOnasNGzZo9uzZ/3G1MQMEAAAAoMPMnj1b55xzTtG2zc3+nHnmmTr22GM/N72RI0fqsssu0/PPP98qnYkTJ+ob3/iG7rjjji2OjwEQAAAAgA7TnuVuAwYM0IABA/7tfr/61a902WWXBa+XL1+uadOmaf78+dpnn33aFR8DIAAAAKAcxeiLUIcPH170ulevXpKk0aNHa7vttmtXWvwPEAAAAIDYYAYIAAAAQFkZOXKkbIkzYAyAAAAAgHLkdHcA5YklcAAAAABigwEQAAAAgNhgCRwAAABQhkyM7gLXkZgBAgAAABAbDIAAAAAAxAZL4AAAAIByxBK4kjADBAAAACA2GAABAAAAiA0GQAAAAABig/8BAgAAAMqRw/8AlYIZIAAAAACxwQAIAAAAQGywBA4AAAAoR9wGuyTMAAEAAACIDQZAAAAAAGKDJXAAAABAOWIJXEmYAQIAAAAQGwyAAAAAAMQGS+AAAACAcsQSuJIwAwQAAAAgNhgAAQAAAIgNlsABAAAA5chhCVwpmAECAAAAEBsMgAAAAADEBkvgAAAAgHJkne6OoCwxAwQAAAAgNhgAAQAAAIgNlsABAAAA5YgvQi0JM0DdyElK+V6SNe7r7BojJyM195EKWSnR7L1npXylu4/xlnom8pJNu8/zlZK8/STJFNyHjGSse4xNSql696cpuPsab39rpHy1l4aRnLSU6yfZlFTIePk1eWnn3TQqPpOcjPszXSctO/kGGceNJdUQ5h+NS9ZNJ5Fz8y5kvXgc9z2bkJyUV2bjvrYJNy2/jqzXY/NVXlyRsvpMwTsu7+UdeSTyUnOV1LiNd3yzW15r3PKagltP6To3LlOQ0pu8OvXScDLucUEdevVr8lIy5+WVcNMc8GpB6Tops8597WTCOP32tWn3uV9OJx22kfXasJCRUnWSk3WPbe7t1Y9x827qE9ZRUz8b1Ic1bp07GTedvm8mg/eSTVLB71defjLuMYWsu781bvmSTe4+fl3V7dYYtKnJh8f59WgTXh/14rMJr539/lzhvpdsjPTHgnusn6aTcY/x+4Rp9h7efolmd7/0xrCv2IRkexWUaHbbcePOzcpscPPNrI/0Bb+veP0u2STlBhZk8mE8w//nM6U3uOWXvHIYL3/ved0w654/FV5aSfch67aRHK89vTSM49a5TXjtkgpjyvVzj+23zAZ93e/bNuX2E5v0+p5X933fMm7ajtRUY4Nz3eTDMkbPv6K29q4N+epIml7/88thjVSo8PuV45arWqr81Dsn8iqqTyctNQx0z0/jSIUq75xJF19vglgc75x2vHPZv155+/h93Jfa5LarsVJ6vRt33YiC+r5rgzSD64dxz0e/7v3zqanGa1MjpRrDWApeG+arwnxNIRKncfu03x/88yGRK+7j2TXhdc2/Fklef232Xvuxetepys9sUD/+eZfIF+8XbUO/Tvx29vvJppFWTf3C9kvVhZ8HTtaN3RSkQjqSpp+WDd+XkbJrEnKSXn6pSB8uRMpri9tKXl+0yUifSIX1aP3reuRPr8G2RJhO5adS74/dwvrXiGST10+aw/aV3DaQIynhXTMi9ZZZ5/Vnvx8Z75xzwmt69LwNrlNO2ObJxvB50F/9+vLaxEm7+SaapWRDeO3y68Em3byj17qEf9309mkYFLZH9BojR9o40gbbmvq6eaXqvT7mSLn+3qGROJur3byae7nXmkKFV2ZHymywRe3U62MbXhe8GPzPDOOEdeqn7X8WqsU54mQi/cFro8wGL81EWBem4L62KTeuzHp3u/97juTWc+MAr42TxW0U/J4Q6UOO9/tQUz/3Z7Le+/3Fa7NUXXG/SzRL2bVhv07ki9ssWq7gGoKtCgOgrZSlZdFFor/sAJ3J/6UE6Gx8hgJbN5bAAQAAAOWIL0ItCX/jAAAAABAbDIAAAAAAxAZL4AAAAIByxF3gSsIMEAAAAIDYYAAEAAAAIDZYAgcAAACUI5bAlYQZIAAAAACxwQAIAAAAQGywBA4AAAAoRyyBKwkzQAAAAABigwEQAAAAgNhgCRwAAABQjhynuyMoS8wAAQAAAIgNBkAAAAAAYoMlcAAAAEA54i5wJWEGCAAAAEBsMAACAAAAEBssgQMAAADKEUvgSsIMEAAAAIDYYAAEAAAAIDZYAgcAAACUI4clcKVgBggAAABAbDAAAgAAABAbLIEDAAAAypC1TneHUJaYAQIAAAAQGwyAAAAAAMQGS+AAAACAcsRd4ErCDBAAAACA2GAABAAAACA2WAIHAAAAlCPLErhSMAMEAAAAIDYYAAEAAACIDZbAAQAAAOXI4YtQS8EMEAAAAIDYYAAEAAAAIDZYAgcAAACUI+4CVxJmgAAAAADEBgMgAAAAALHBEjgAAACgDFnuAlcSZoAAAAAAxAYDIAAAAACxwRI4AAAAoBxxF7iSMAMEAAAAIDYYAAEAAACIDZbAAQAAAOXIYQlcKZgBAgAAABAbDIAAAAAAxAZL4AAAAIByZPki1FIwAwQAAAAgNhgAAQAAAIgNlsABAAAAZchyF7iSMAMEAAAAIDYYAAEAAACIDZbAAQAAAOWIu8CVhBkgAAAAALHBAAgAAABAbLAEDgAAAChD3AWuNMwAAQAAAIgNBkAAAAAAYoMlcAAAAEA54i5wJWEGCAAAAEBsGGst/z3VDXK5nC699FLl83lJUiqV0kUXXaRsNtvNkQEAAABbLwZA3WTDhg2qqakp2rZ+/Xr16dOnmyICAAAAtn4sgQMAAAAQGwyAAAAAAMQGAyAAAAAAscFtsLtJNpvVhRdeWHQTBG6AAAAAAHQuboIAAAAAIDZYAgcAAAAgNhgAAQAAAIgNBkAAAAAAYoMBEAAAAIDYYADUxZqamrRs2bLg7m8AAAAAug4DoC5SX1+vk08+WRUVFdppp530+uuvS5JmzZqlK6+8UpK0YcMG/dd//Vd3hgkAAABs1bgNdhepqKhQPp9XoVCQJPXu3VupVErNzc1qaGhQnz595DiO1q9fL5oEAAAA6BzMAHWR6upqnXLKKdppp50kSY7jaJ999tFxxx2nRCKhvffeW7lcTv369evmSAEAAICtFzNAXaSqqkqNjY2SFMzwGGOC18YYJZNJ7brrrnr55Ze7LU4AAABga8YMUBfZa6+99OMf/7hoeZu1NnhtrVU+n9fbb7/dXSECAAAAWz0GQF1kzpw5+tnPfqbTTjtNknTAAQdoypQpqq6u1osvvihrrX7605+qtra2myMFAAAAtl4sgetCr732mq655ho99thjWr58ubbZZhvtu+++6t27t9566y394x//0Jlnnqlrr722u0MFAAAAtkoMgLrBvffeq29/+9uqr68v2p5IuBNy/p3iAAAAAHQslsB1IcdxdPXVV+v4449XVVWVvv3tbyudTmvvvfdWMpnUqFGj9NRTT3V3mAAAAMBWixmgLvL444/rO9/5jt5///0237/88st1/fXXq3///nr11Ve7ODoAAAAgHhgAdRFjjGbMmKFHH31Uzc3NMsbIGCPHcYqeS+KLUAEAAIBOwgCoi1RUVGjx4sU6/PDD1djYqNNOO00HHnigLr30Um3cuFGjRo3SAw88oEGDBm12lggAAADAf4b/Aeoi+++/vz744AOde+65+uSTT/TMM8/oo48+0mGHHaa33npL8+fPVzKZ1K233trdoQIAAABbLWaAOlH0f3neffdd/fCHP9T555+vzz77TL/97W/13nvvyXEcbbvttvrmN7+p6dOnyxij3XbbrRujBgAAALZeDIA6USKRkDGm1f/0tFXl/i2wJW6DDQAAAHSWVHcHsDVr6395DjzwQO2000567bXXVFNTo7feeksDBgyQtVafffaZBg0a1A2RAgAAAPHA/wB1ohEjRuiSSy5R//79NWLECI0YMUL//Oc/9de//lX5fF5HHnmkMpmMvvOd7+iss85SIpFQVVVVd4cNAAAAbLUYAHWyO+64Qw0NDXrggQf0wAMPSJJyuZxOOeUUTZo0STU1NaqurtbKlSs1YsQIrVy5spsjBgAAALZe/A9QJ0skElq5cqUGDx4sSUXf9+P/f1AikdCIESP0hS98QS+//LLefffd7gwZAAAA2GrxP0BdIDroGTVqlCZPnqzXX39dTz/9tJYtW6Zp06bpww8/1IoVKzRv3rzuDRYAAADYijED1MkSiYRqamq0cePGou3+nd78O8WNGTNGmUxGqVRK//jHP7ojVAAAAGCrxwxQF7jkkkv05JNPSnK/G6i6ulqjR48O3vfvANfY2KgZM2Z0V5gAAADAVo8ZoE7m/w/QwIEDJUnbbrutvvjFL+qQQw7Rt771LRUKBR100EF67rnnJElPPPGEJk+e3I0RAwAAAFsv7gLXyYwxRa9Xr16t3//+9xoxYoQk6c9//rM++OAD/eUvf5ExRoceemh3hAkAAADEAgOgTtZygm3MmDEqFAoaMGCAJOnhhx/WMccco6VLl2rYsGHK5XLdESYAAAAQCwyAOpnjOMHytwceeED/9V//JUk644wzdNlll+n3v/+9XnrpJZ133nkaOHCgEgmaBAAAAOgs/A9QF/IHN21VeSqVUm1trfr27aulS5d2dWgAAABALHAXuC4U/S6giy66SP/617/03//93xo7dqwk6Y477lDfvn27MUIAAABg68YAqAutXbtWv/jFL/T+++/r008/1eTJk3X33XeroqJCqVRKyWRSCxcu7O4wAQAAgK0WA6AudOaZZ2rRokX65z//qTvvvDP4MlRJymQyyufzOumkk7RgwYLuCxIAAADYivE/QF2opqZGo0aN0saNG3XdddfpsMMO04MPPihjjGbNmqVsNquPPvpIGzdu7O5QAQAAgK0StxzrZMcff7yWL18uSdq0aZPeffdd3Xrrrfryl78sSaqurtZhhx2mW265Rf/85z+1adOm7gwXAAAA2KoxAOpk9913nz7++GNJ7k0QcrmcBg0aJEnauHGjJk+eLEkaOHCgGhsbuytMAAAAIBZYAteFMpmMBg8erH333Vd33nmnKioqJEkNDQ068cQT9fzzz2vFihVqbm7u5kgBAACArRMDoC40YcIEvfnmmxowYICampq0++67yxijxYsXK5PJ6LPPPtMuu+yixYsXd3eoAAAAwFaJAVAXev3114NBz84776zKykoZY1RfX68lS5bIWqtXXnlFu+66a3eHCgAAAGyVGAB1sb/+9a/6yle+otWrVxdtr62t1R//+Mfgf4IAAAAAdDwGQF3ggQceaLVtxYoVeuONNyRJ48aN05AhQyRJRxxxRJfGBgAAAMQJA6AukEgU32zPGKOW1W6MkaSiL0cFAAAA0LG4DXYXcBwneCxcuFATJkzQI488onXr1mn9+vV65JFH9IUvfEGPPvpod4cKAAAAbNWYAepiu+66q2688UYdcMABRdufeeYZffe739WSJUu6KTIAAABg68cMUBd79913VVNT02p7TU2NPvjgg64PCAAAAIgRZoC62EEHHaR0Oq277747uPHBypUrdcIJJ6ipqUlPP/10N0cIAAAAbL0YAHWxd955R0cffbSWLVum4cOHS5I+/PBD7bjjjlqwYIHGjBnTzRECAAAAWy8GQN3AWqvHHnss+PLTXXbZRVOmTAnuBAcAAACgc/A/QF2koaFBDz74oCT3ltdPPPGEPvjgA3344Yd65JFHdMEFF6ixsbGbowQAAAC2bqnuDiAu7rzzTj344IM6/PDDJUnXXXedxo0bp8rKSknS0qVLNWTIEJ199tndGSYAAACwVWMJXBc56KCDdPbZZ+voo4+WJPXu3VuvvPKKtt9+e0nS3XffrV//+td67rnnujNMAAAAYKvGErhOdOONN2rjxo2SpLfeektjx47d7L5777233nzzza4KDQAAAIglBkCd6LrrrtO6deskSevXr1cqFa44XL16dTD7I0mO4yiXy3V1iAAAAECsMADqRK+//rqGDRsmSdpuu+30+uuvB+9lMpmifV999VVtt912XRofAAAAEDcMgLrIYYcdph/96Edt3umtoaFBl1xyiaZPn94NkQEAAADxwU0Qusgnn3yiCRMmKJPJ6Mwzz9TYsWNljNHSpUt13XXXKZ/P6+WXX9agQYO6O1QAAABgq8UAqAu9//77Ov3007Vo0SL51W6M0dSpU3X99dcX/U8QAAAAgI7HAKgbrFmzRu+8844kacyYMerfv383RwQAAADEAwMgAAAAALHBTRAAAAAAxAYDIAAAAACxwQAIAAAAQGwwAAIAbDFjjBYsWNDdYQAAUDIGQAAQI8aYz32cdNJJ3R0iAACdKtXdAQAAus6KFSuC5/Pnz9ePfvQjLVu2LNhWWVnZHWEBANBlmAECgBgZPHhw8KipqZExpmjbPffco9GjRyuTyWjHHXfUXXfd9bnp/eQnP9GgQYO0ePFiSdKzzz6rgw46SJWVlRo2bJhmzZqlurq6YP+RI0fqiiuu0CmnnKLevXtr+PDhuvnmm4P3m5qadOaZZ2rIkCGqqKjQyJEjNWfOnE6pCwBAPDEAAgBIku6//36dddZZOvfcc/X666/r1FNP1cknn6wnn3yy1b7WWp111lm69dZb9be//U0TJkzQa6+9pmnTpukrX/mKXn31Vc2fP19/+9vfdOaZZxYd+7Of/UwTJ07Uyy+/rDPOOEOnn366li5dKkn61a/+//buGCS1Pozj+C+tIZKIJoOGwiAkiBCCQKQgopai4uCJQGmJguBQQzQ0RVM0RLepKaGmhKCioHSJpJYCG0TCwamlIVqk7fgOvfeAt3e4cHvv8v9+4IA8PEf/f7ffeY7HHzo7O9Px8bGen591dHSkjo6Ov7F9AIAh+CNUADBUKpXS8vKy3t/fJUnRaFQ9PT01E5l4PK5KpaKLiwtJn78hSqfTOj091cPDgzKZjNrb2yVJyWRSjY2N2t/f987P5XIaHBxUpVLxJjqxWMybLFWrVQWDQW1sbGhxcVGO46hQKCibzaquru4vfRMAAJMwAQIASJKKxaKi0WhNLRqNqlgs1tRWVlZ0f3+v29tbL/xI0uPjo1KplAKBgHeMjo7KdV2Vy2Wvr7e313v98xa819dXSdLc3Jzy+by6u7vlOI6ur6//j60CAAxGAAIAeH6dulSr1S+1kZERvby86Orqqqbuuq4WFhaUz+e94+npSaVSSaFQyOtraGj48pmu60qSIpGIyuWyNjc39fHxoXg8LsuyvnOLAADD8RQ4AIAkKRwOK5fLKZlMerW7uzuFw+GavomJCY2Pj2t2dlZ+v18zMzOSPsNLoVBQV1fXH62jublZtm3Ltm1ZlqWxsTG9vb2ptbX1j94XAACJAAQA+Nfq6qri8bgikYiGh4d1fn6uk5MTZbPZL71TU1M6PDxUIpFQfX29LMvS2tqaBgYGtLS0pPn5eTU1NalYLCqTyWhvb++31rCzs6O2tjb19fXJ5/MpnU4rGAyqpaXlm3cLADAVAQgAIEmanJzU7u6utre35TiOOjs7dXBwoKGhof/styxLrusqkUjI5/NpenpaNzc3Wl9fVywWU7VaVSgUkm3bv72GQCCgra0tlUol+f1+9ff36/LyUj4fd2wDAL4HT4EDAAAAYAwuqQEAAAAwBgEIAAAAgDEIQAAAAACMQQACAAAAYAwCEAAAAABjEIAAAAAAGIMABAAAAMAYBCAAAAAAxiAAAQAAADAGAQgAAACAMQhAAAAAAIxBAAIAAABgjH8AqtxDzX90+Q8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = AttentionDiffMask(config=config, device=get_device())\n",
    "  \n",
    "# 假设有一个批次的数据\n",
    "originals = [\"The doctor said that\"]\n",
    "counterfactuals = [\"The nurse said that\"]\n",
    "\n",
    "mask = torch.ones((len(originals), dm.model.cfg.n_layers, dm.model.cfg.n_heads))\n",
    "\n",
    "# 执行干预并获取注意力权重\n",
    "dm.intervene(originals, counterfactuals, mask)\n",
    "\n",
    "# 获取原始句子的 tokens\n",
    "tokens = dm.model.tokenizer.tokenize(originals[0])\n",
    "\n",
    "# 可视化第0层第0个注意力头的权重\n",
    "visualize_attention(dm.attention_weights, layer=0, head=0, sentence=originals[0], tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cef58a2f-0615-4ebd-a901-eb63f4284c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'Ġdoctor', 'Ġsaid', 'Ġthat']\n"
     ]
    }
   ],
   "source": [
    "tokens = dm.model.tokenizer.tokenize(originals[0])\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd6e2165-eea3-4568-b33e-dce3746e01c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoctor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m pruned_attention_weights \u001b[38;5;241m=\u001b[39m prune_attention_weights(dm\u001b[38;5;241m.\u001b[39mattention_weights, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mvisualize_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpruned_attention_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mvisualize_attention\u001b[0;34m(attention_weights, layer, head, tokens, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_attention\u001b[39m(attention_weights, layer, head, tokens, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m     attention \u001b[38;5;241m=\u001b[39m \u001b[43mattention_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m     attention \u001b[38;5;241m=\u001b[39m attention \u001b[38;5;241m*\u001b[39m (attention \u001b[38;5;241m>\u001b[39m threshold)  \u001b[38;5;66;03m# 仅显示高于阈值的权重\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     sns\u001b[38;5;241m.\u001b[39mheatmap(attention, xticklabels\u001b[38;5;241m=\u001b[39mtokens, yticklabels\u001b[38;5;241m=\u001b[39mtokens, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def prune_attention_weights(attention_weights, threshold=0.1):\n",
    "    pruned_attention_weights = []\n",
    "    for layer_weights in attention_weights:\n",
    "        pruned_layer_weights = []\n",
    "        for head_weights in layer_weights:\n",
    "            pruned_head_weights = head_weights * (head_weights > threshold)\n",
    "            pruned_layer_weights.append(pruned_head_weights)\n",
    "        pruned_attention_weights.append(pruned_layer_weights)\n",
    "    return pruned_attention_weights\n",
    "\n",
    "pruned_attention_weights = prune_attention_weights(dm.attention_weights, threshold=0.1)\n",
    "\n",
    "def visualize_attention(attention_weights, layer, head, tokens, threshold=0.1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    attention = attention_weights[layer][0, head, :, :].numpy()\n",
    "    attention = attention * (attention > threshold)  # 仅显示高于阈值的权重\n",
    "    sns.heatmap(attention, xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "    plt.title(f'Attention weights for layer {layer}, head {head}')\n",
    "    plt.xlabel('Tokens')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "# 示例调用\n",
    "tokens = [\"The\", \"doctor\", \"said\", \"that\"]\n",
    "pruned_attention_weights = prune_attention_weights(dm.attention_weights, threshold=0.1)\n",
    "visualize_attention(pruned_attention_weights, layer=0, head=0, tokens=tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321baac-ea82-49c3-af1f-f6ec8778b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
