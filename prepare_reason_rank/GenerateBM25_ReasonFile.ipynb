{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa5e466-3d94-4196-9a2f-f9474a2adfbc",
   "metadata": {},
   "source": [
    "# Generate BM 25 for the different datasets\n",
    "Covid, NFCorpus, Touche, DBPedia, SciFact, MS Marco, Novel eval.\n",
    "\n",
    "https://github.com/beir-cellar/beir?tab=readme-ov-file\n",
    "\n",
    "https://github.com/sunnweiwei/RankGPT/tree/main/NovelEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b4c43c-f12a-435b-bcc6-a5149f47aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuj49/anaconda3/envs/llama_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "# Build up the bm25 searching engine of the pyserini\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.index.lucene import IndexReader\n",
    "import json\n",
    "import openai\n",
    "import re\n",
    "import pandas as pd\n",
    "# from load_selfknowledge import simple_search_with_context_bert\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm \n",
    "\n",
    "from pyserini.search import LuceneSearcher, get_topics, get_qrels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25e9b80-e0f4-4169-98b8-40e22ec8b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_list = {\n",
    "    # \"nfcorpus\":{\n",
    "    #     \"train_query\":\"../data/nfcorpus/train.nontopic-titles.queries\",\n",
    "    #     \"train_qrel\":\"../data/nfcorpus/train.2-1-0.qrel\",\n",
    "    #     \"knowledge_base\":'beir-v1.0.0-nfcorpus.flat'},\n",
    "    # \"covid\": {\n",
    "    #     \"train_query\":\"../data/trec_covid/queries.jsonl\",\n",
    "    #     \"train_qrel\":\"../data/trec_covid/qrels/test.tsv\",\n",
    "    #     \"knowledge_base\": \"beir-v1.0.0-trec-covid.flat\"},\n",
    "    # \"touche\":{\n",
    "    #     \"train_query\":\"../data/touche/queries.jsonl\",\n",
    "    #     \"train_qrel\":\"../data/touche/qrels/test.tsv\",\n",
    "    #     \"knowledge_base\": \"beir-v1.0.0-webis-touche2020.flat\"},\n",
    "    # \"dbpedia\":{\n",
    "    #     \"train_query\":\"../data/dbpedia-entity/queries.jsonl\",\n",
    "    #     \"train_qrel\":\"../data/dbpedia-entity/qrels/test.tsv\",\n",
    "    #     \"test_qrel\":\"../data/dbpedia-entity/qrels/dev.tsv\",\n",
    "    #     \"knowledge_base\": \"beir-v1.0.0-dbpedia-entity.flat\"},\n",
    "    # \"scifact\":{\n",
    "    #     \"train_query\":\"../data/scifact/queries.jsonl\",\n",
    "    #     \"train_qrel\":\"../data/scifact/qrels/train.tsv\",\n",
    "    #     \"test_qrel\": \"../data/scifact/qrels/test.tsv\",\n",
    "    #     \"knowledge_base\":\"beir-v1.0.0-scifact.flat\"},\n",
    "    \"msmarco\":{\n",
    "        \"train_query\":\"../data/msmarco/queries.jsonl\",\n",
    "        \"train_qrel\":\"../data/msmarco/qrels/train.tsv\",\n",
    "        \"test_qrel\":\"../data/msmarco/qrels/test.tsv\",\n",
    "        \"dev_qrel\":\"../data/msmarco/qrels/dev.tsv\",\n",
    "        \"knowledge_base\": \"msmarco-v1-passage\"},\n",
    "    # \"noval\":{\n",
    "    #     \"train_query\":\"../data/Noveleval/queries.tsv\",\n",
    "    #     \"train_qrel\":\"../data/Noveleval/qrel.txt\",\n",
    "    #     \"corpus\": \"../data/Noveleval/corpus.tsv\"},      \n",
    "}\n",
    "\n",
    "\n",
    "def retrieve_documents(query, knowledge_base='beir-v1.0.0-nfcorpus.flat', top_n=20):\n",
    "    # initialize the retrieval\n",
    "    # problem here is the knowledge is too long\n",
    "    searcher = LuceneSearcher.from_prebuilt_index(knowledge_base)\n",
    "    index_reader = IndexReader.from_prebuilt_index(knowledge_base)\n",
    "    hits = searcher.search(query, k=top_n)\n",
    "    documents = []\n",
    "    if knowledge_base == \"msmarco-v1-passage\":\n",
    "        for i, hit in enumerate(hits):\n",
    "            docid = hit.docid\n",
    "            score = hit.score\n",
    "            raw_document = searcher.doc(docid).raw()\n",
    "            raw_document = json.loads(raw_document)\n",
    "            raw_document = raw_document[\"contents\"]\n",
    "            documents.append({\"docid\": docid, \"content\": raw_document})\n",
    "           \n",
    "    else:\n",
    "        for i, hit in enumerate(hits):\n",
    "            docid = hit.docid\n",
    "            score = hit.score\n",
    "            raw_document = searcher.doc(docid).raw()\n",
    "            raw_document = json.loads(raw_document)[\"text\"]\n",
    "            documents.append({\"docid\": docid, \"content\": raw_document})\n",
    "            \n",
    "    return documents\n",
    "\n",
    "def write_query_qrel(query_file, qrel_file, knowledge_base=\"msmarco-v1-passage\", data_name=\"msmarco\", data_type=\"test\", train_limit=100):    \n",
    "    query_used = []\n",
    "    # qrel file suppose to be the tsv file \n",
    "    with open(qrel_file,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        qrel_res = []\n",
    "        if data_type == \"train\" and train_limit:\n",
    "            lines = lines[:train_limit]\n",
    "        if knowledge_base in[\"msmarco-v1-passage\",\"beir-v1.0.0-scifact.flat\",\"beir-v1.0.0-webis-touche2020.flat\",\"beir-v1.0.0-trec-covid.flat\", \"beir-v1.0.0-dbpedia-entity.flat\"]:\n",
    "            for line in lines:\n",
    "                item = {}\n",
    "                query_id = line.split(\"\\t\")[0]\n",
    "                doc_id = line.split(\"\\t\")[1]\n",
    "                score = line.split(\"\\t\")[-1].strip()\n",
    "                item[\"query_id\"] = query_id\n",
    "                query_used.append(query_id)\n",
    "                item[\"doc_id\"] = doc_id\n",
    "                item[\"score\"] = score\n",
    "                qrel_res.append(item)\n",
    "        else:\n",
    "            for line in lines:\n",
    "                item = {}\n",
    "                query_id = line.split(\"\\t\")[0]\n",
    "                doc_id = line.split(\"\\t\")[2]\n",
    "                score = line.split(\"\\t\")[-1].strip()\n",
    "                item[\"query_id\"] = query_id\n",
    "                query_used.append(query_id)\n",
    "                item[\"doc_id\"] = doc_id\n",
    "                item[\"score\"] = score\n",
    "                qrel_res.append(item)\n",
    "\n",
    "    # query file suppose to be the jsonl file \n",
    "    with open(query_file,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        retrieval_json = []\n",
    "        index = 0\n",
    "        if data_name == \"nfcorpus\":\n",
    "            for line in lines:\n",
    "                index+=1\n",
    "                query_item = {}\n",
    "                query_id = line.split(\"\\t\")[0]\n",
    "                if query_id in query_used:\n",
    "                    query = line.split(\"\\t\")[1].strip()\n",
    "                    documents = retrieve_documents(query, knowledge_base)\n",
    "                    documents = find_score(qrel_res, documents, query_id)\n",
    "                    query_item[\"hits\"] = documents\n",
    "                    query_item[\"query\"] = query\n",
    "                    query_item[\"query_id\"] = query_id\n",
    "                    retrieval_json.append(query_item)\n",
    "        else:\n",
    "            for line in lines:\n",
    "                line = json.loads(line)\n",
    "                query_item = {}\n",
    "                query_id = line[\"_id\"]\n",
    "                if query_id in query_used:\n",
    "                    query = line[\"text\"]\n",
    "                    documents = retrieve_documents(query, knowledge_base)\n",
    "                    documents = find_score(qrel_res, documents, query_id)\n",
    "            \n",
    "            \n",
    "                    query_item[\"hits\"] = documents\n",
    "                    query_item[\"query\"] = query\n",
    "                    query_item[\"query_id\"] = query_id\n",
    "                    retrieval_json.append(query_item)\n",
    "            \n",
    "    with open(f\"../data/BM25/bm25_{data_name}_{data_type}.json\", \"w\") as f:\n",
    "        json.dump(retrieval_json, f)\n",
    "\n",
    "def find_score(qrel_res, documents, query_id):\n",
    "    for doc in documents:\n",
    "        docid = doc[\"docid\"]\n",
    "        flag = False\n",
    "        for item in qrel_res:\n",
    "            if item[\"doc_id\"] == docid and item[\"query_id\"] == query_id:\n",
    "                doc[\"score\"]= item[\"score\"]\n",
    "                flag=True\n",
    "        if flag is False:\n",
    "            doc[\"score\"]= \"0\"\n",
    "            \n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fa2782-87f3-40d9-a17a-f61d69b903f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_name, file_list in dataset_list.items():\n",
    "    # knowledge_based = data_type\n",
    "    \n",
    "    if \"knowledge_base\" in file_list.keys():\n",
    "        knowledge_base = file_list[\"knowledge_base\"]\n",
    "    train_query = file_list[\"train_query\"]\n",
    "    train_qrel = file_list[\"train_qrel\"]\n",
    "    \n",
    "    write_query_qrel(train_query, train_qrel, knowledge_base, data_name ,data_type = \"train\", train_limit=10000)\n",
    "    if \"test_qrel\" in file_list.keys():\n",
    "        test_qrel = file_list[\"test_qrel\"]\n",
    "        # If using test, the train_limit must set None\n",
    "        # write_query_qrel(train_query, test_qrel, knowledge_base,data_name, data_type = \"test\",  train_limit=None) \n",
    "    if \"dev_qrel\" in file_list.keys():\n",
    "        dev_qrel = file_list[\"dev_qrel\"]\n",
    "        write_query_qrel(train_query, dev_qrel, knowledge_base,data_name, data_type = \"dev\",  train_limit=None) \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138965c-32db-4010-a619-966ecec8588c",
   "metadata": {},
   "source": [
    "# Prepare reason files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31ca2a9-431b-4cc0-b6ee-1958212ca400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the reasons from the paper: https://arxiv.org/abs/2304.09542 \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_gpt_reason import sliding_windows, create_permutation_instruction, run_llm, receive_permutation\n",
    "import copy\n",
    "\n",
    "\n",
    "api_key = \"sk-proj-9DfFb55gEDX2knzRbykaT3BlbkFJlsVHV2DoNw8pfuSwtdhB\"\n",
    "\n",
    "# gpt-4\n",
    "def single_search(item=None, rank_start=0, rank_end=100, model_name='gpt-3.5-turbo', api_key=api_key):\n",
    "  query = item[\"query\"]\n",
    "  # (1) Create permutation generation instruction\n",
    "  messages = create_permutation_instruction(item=item, rank_start=rank_start, rank_end=rank_end, model_name=model_name)\n",
    "  # (2) Get ChatGPT predicted permutation\n",
    "  permutation = run_llm(messages, api_key=api_key, model_name=model_name)\n",
    "  # (3) Use permutation to re-rank the passage\n",
    "  reasoning = permutation\n",
    "  def clean_reason(permutation):\n",
    "      # 找到第一次出现的排名序列\n",
    "      ranking_pattern = re.findall(r'\\[\\d+\\] >', permutation)\n",
    "      new_response = \"\"\n",
    "      # 提取这些模式中的数字\n",
    "      ranking_numbers = [int(num) for pattern in ranking_pattern for num in re.findall(r'\\d+', pattern)]\n",
    "      new_response = \" \".join([str(i )for i in ranking_numbers])\n",
    "      # 单独处理最后一个排名元素\n",
    "      # 查找文本中的最后一个 [数字] 模式\n",
    "      last_number_match = re.search(r'\\[\\d+\\](?!.*\\[\\d+\\])', permutation)\n",
    "      if last_number_match:\n",
    "          last_number = last_number_match.group().strip('[]')\n",
    "          new_response +=  \" \" + last_number\n",
    "          # ranking_numbers.append(str(last_number))\n",
    "      return new_response\n",
    "  res = clean_reason(permutation)\n",
    "  response_id = []\n",
    "  res = res.split()\n",
    "  # item[\"hits\"] = item[\"hits\"][rank_start: rank_end]\n",
    "  for i in res:\n",
    "      response_id.append(item[\"hits\"][int(i)-1][\"docid\"])\n",
    "  unsorted_docs = []\n",
    "  for j in item[\"hits\"][rank_start: rank_end]:\n",
    "    unsorted_docs.append(j[\"content\"])\n",
    "\n",
    "  scores = []\n",
    "  for k in item[\"hits\"][rank_start: rank_end]:\n",
    "    scores.append(k[\"score\"])\n",
    "  return_format = {\"query\":query,\n",
    "                   \"sorted_docids\":response_id,\n",
    "                   \"re_rank_id\":res,\n",
    "                   \"unsorted_docs\": unsorted_docs,\n",
    "                   \"reason\": reasoning ,\n",
    "                   \"scores\": scores}\n",
    "  return return_format\n",
    "\n",
    "# fix with the current sliding window\n",
    "def file_search(json_file, rank_start=0, rank_end=3,window_size=20, step=10, model_name='gpt-3.5-turbo'):\n",
    "    return_format = []\n",
    "    for item in tqdm(json_file):\n",
    "      res= single_search(item, rank_start=rank_start, rank_end=rank_end, model_name=model_name)\n",
    "      return_format.append(res)\n",
    "    return return_format\n",
    "\n",
    "\n",
    "def sliding_windows(item=None, rank_start=0, rank_end=100, window_size=20, step=10, model_name='gpt-3.5-turbo',\n",
    "                    api_key=None):\n",
    "    slide_item = copy.deepcopy(item)\n",
    "    end_pos = rank_end\n",
    "    start_pos = rank_end - window_size\n",
    "    res = []\n",
    "    while start_pos >= rank_start:\n",
    "        start_pos = max(start_pos, rank_start)\n",
    "        \n",
    "        new_item = single_search(slide_item, start_pos, end_pos, model_name=model_name, api_key=api_key)\n",
    "        end_pos = end_pos - step\n",
    "        start_pos = start_pos - step\n",
    "        res.append(new_item)\n",
    "    return res\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd79c262-0550-4583-8a25-2945a741a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "#Load BM25 \n",
    "bm25_list = {\n",
    "    # \"nfcorpus\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_nfcorpus_train.json\"}\n",
    "    # \"covid\": {\n",
    "    #     \"train\":\"../data/BM25/bm25_covid_train.json\"\n",
    "    #    },\n",
    "    # \"touche\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_touche_train.json\"}\n",
    "    # \"dbpedia\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_dbpedia_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_dbpedia_test.json\"},\n",
    "    # \"scifact\":{\n",
    "    #     \"train\":\"../data/BM25/bm25_scifact_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_scifact_test.json\"},\n",
    "    \"msmarco\":{\n",
    "        \"train\":\"../data/BM25/bm25_msmarco_train.json\",\n",
    "        \"test\":\"../data/BM25/bm25_msmarco_test.json\",\n",
    "        \"dev\":\"../data/BM25/bm25_msmarco_dev.json\"},\n",
    "    # \"noval\":{\n",
    "    #    \"train\":\"../data/BM25/bm25_noval_train.json\",\n",
    "    #     \"test\":\"../data/BM25/bm25_noval_test.json\"}     \n",
    "}\n",
    "\n",
    "\n",
    "# nf = json.load(open(nf_file))\n",
    "# touche = json.load(open(touche_file))\n",
    "# trec_covid = json.load(open(trec_covid_file))\n",
    "\n",
    "\n",
    "def file_single_search(json_file, rank_start=0, rank_end=5, model_name='gpt-3.5-turbo', data_name=\"msmarco\", data_type = \"train\"):\n",
    "    return_format = []\n",
    "    file_path = f'../data/{model_store}/{data_name}_{data_type}.jsonl'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    model_store = \"GPT3.5\" if model_name == 'gpt-3.5-turbo' else \"GPT4\"\n",
    "    for item in tqdm(json_file):\n",
    "      res= sliding_windows(item, rank_start=rank_start, rank_end=rank_end, model_name=model_name)\n",
    "      return_format.append(res)\n",
    "      with open(file_path, 'a') as f:\n",
    "       for res in return_format:\n",
    "            json.dump(res, f)\n",
    "            f.write('\\n')\n",
    "    return return_format\n",
    "\n",
    "\n",
    "def file_sliding_search(json_file, rank_start=0, rank_end=20, window_size=5, step=5, model_name='gpt-3.5-turbo',data_name=\"msmarco\", data_type = \"train\", index=None):\n",
    "    return_format = []\n",
    "    model_store = \"GPT3.5\" if model_name == 'gpt-3.5-turbo' else \"GPT4\"\n",
    "    if index:\n",
    "        \n",
    "        file_path = f'../data/{model_store}/{data_name}_{data_type}_{str(index)}.jsonl'\n",
    "    else:\n",
    "        file_path = f'../data/{model_store}/{data_name}_{data_type}.jsonl'\n",
    "    \n",
    "    # if os.path.exists(file_path):\n",
    "    #     os.remove(file_path)\n",
    "    for item in tqdm(json_file):\n",
    "      res= sliding_windows(item=item, rank_start=rank_start, rank_end=rank_end, window_size=window_size, step=step, model_name=model_name, api_key=api_key)\n",
    "      # print(res)\n",
    "      return_format.append(res)\n",
    "    # print(return_format)\n",
    "    \n",
    "    with open(file_path, 'a') as f:\n",
    "        for res in return_format:\n",
    "            for r in res:\n",
    "                json.dump(r, f)\n",
    "                f.write('\\n')\n",
    "    return return_format\n",
    "    \n",
    "for data_name, data in bm25_list.items():\n",
    "     \n",
    "    if \"test\" in data.keys():\n",
    "        test_data = data[\"test\"]\n",
    "        test_data = json.load(open(test_data))\n",
    "        test_data = test_data \n",
    "        # Note here there will be 20/5 = 4 for each query \n",
    "        file_sliding_search(test_data, rank_start=0, rank_end=20, window_size=5, step=5, model_name='gpt-4',data_name=data_name, data_type=\"test\")\n",
    "\n",
    "    # if \"dev\" in data.keys():\n",
    "    #     dev_data = data[\"dev\"]\n",
    "    #     dev_data = json.load(open(dev_data))\n",
    "    #     file_sliding_search(dev_data, rank_start=0, rank_end=20, window_size=5, step=5, model_name='gpt-3.5-turbo',data_name=data_name, data_type=\"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787df362-8eda-431d-b809-da24dd91b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin index 0\n",
      "end index 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [26:23<00:00, 15.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin index 100\n",
      "end index 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 100/100 [27:02<00:00, 16.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin index 200\n",
      "end index 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [27:08<00:00, 16.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin index 300\n",
      "end index 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████▎                                            | 23/100 [06:13<21:57, 17.11s/it]"
     ]
    }
   ],
   "source": [
    "# range length 0-9365\n",
    "\n",
    "for data_name, data in bm25_list.items():\n",
    "    train_data = data[\"train\"]\n",
    "    train_data = json.load(open(train_data))\n",
    "    total_length = len(train_data)\n",
    "    step2train = 100\n",
    "    ranges = total_length //step2train\n",
    "    # print(ranges) # 93\n",
    "    for idx in range(0, ranges): # right now we have 100, 200, we hope begin at 200 so we begin at 2\n",
    "        begin_index = idx*step2train\n",
    "        end_index = (idx+1)*step2train\n",
    "        print(\"begin index\", begin_index)\n",
    "        print(\"end index\", end_index)\n",
    "        temp_train_data = train_data[begin_index:end_index]\n",
    "\n",
    "        file_sliding_search(temp_train_data, rank_start=0, rank_end=10, window_size=5, step=5, model_name='gpt-4',data_name=data_name, data_type=\"train\", index=end_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a13f4-a286-406f-9acd-f801f58cd941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe331b-72e0-4d78-b3b0-71ffd0374dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
